<!doctype html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  
    
      
    

    
  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Fredericka the Great:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hadoop,hadoop原理及其搭建," />





  <link rel="alternate" href="/atom.xml" title="Chant" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="hadoop从运行机制到搭建，加网上常见的天气、好友推荐及协同过滤案列的实践。">
<meta property="og:type" content="article">
<meta property="og:title" content="HADOOP--hadoop运行原理及其搭建">
<meta property="og:url" content="http://chant00.com/2016/11/08/HADOOP--hadoop运行原理及其搭建/index.html">
<meta property="og:site_name" content="Chant">
<meta property="og:description" content="hadoop从运行机制到搭建，加网上常见的天气、好友推荐及协同过滤案列的实践。">
<meta property="og:image" content="http://chant00.com/media/15047669347861.jpg">
<meta property="og:image" content="http://chant00.com/media/15047669465372.jpg">
<meta property="og:image" content="http://chant00.com/media/15047669842275.jpg">
<meta property="og:image" content="http://chant00.com/media/15047670576624.jpg">
<meta property="og:image" content="http://chant00.com/media/15047670965346.jpg">
<meta property="og:image" content="http://chant00.com/media/15047671569429.jpg">
<meta property="og:image" content="http://chant00.com/media/15047677025181.jpg">
<meta property="og:image" content="http://chant00.com/media/15047678033762.jpg">
<meta property="og:image" content="http://chant00.com/media/15047678133842.jpg">
<meta property="og:image" content="http://chant00.com/media/15047678410192.jpg">
<meta property="og:image" content="http://chant00.com/media/15047678977458.jpg">
<meta property="og:image" content="http://chant00.com/media/15047679401077.jpg">
<meta property="og:image" content="http://chant00.com/media/15047684860948.jpg">
<meta property="og:image" content="http://chant00.com/media/15047685351341.jpg">
<meta property="og:image" content="http://chant00.com/media/15047686581032.jpg">
<meta property="og:image" content="http://chant00.com/media/15047688486656.jpg">
<meta property="og:image" content="http://chant00.com/media/15047688732629.jpg">
<meta property="og:image" content="http://chant00.com/media/15047696336748.jpg">
<meta property="og:image" content="http://chant00.com/media/15047700236821.jpg">
<meta property="og:image" content="http://chant00.com/media/15047703288204.jpg">
<meta property="og:image" content="http://chant00.com/media/15047703474873.jpg">
<meta property="og:image" content="http://chant00.com/media/15047703774393.jpg">
<meta property="og:image" content="http://chant00.com/media/15047703934909.jpg">
<meta property="og:image" content="http://chant00.com/media/15047704421563.jpg">
<meta property="og:image" content="http://chant00.com/media/15047704806769.jpg">
<meta property="og:image" content="http://chant00.com/media/15047725214328.jpg">
<meta property="og:image" content="http://chant00.com/media/15047726233991.jpg">
<meta property="og:image" content="http://chant00.com/media/15047726886506.jpg">
<meta property="og:image" content="http://chant00.com/media/15047727091464.jpg">
<meta property="og:image" content="http://chant00.com/media/15047755445312.jpg">
<meta property="og:image" content="http://chant00.com/media/15047755620372.jpg">
<meta property="og:image" content="http://chant00.com/media/15047755831091.jpg">
<meta property="og:image" content="http://chant00.com/media/15047755995512.jpg">
<meta property="og:image" content="http://chant00.com/media/15047845502828.jpg">
<meta property="og:image" content="http://chant00.com/media/15047845869358.jpg">
<meta property="og:image" content="http://chant00.com/media/15047846573345.jpg">
<meta property="og:image" content="http://chant00.com/media/15047848080086.jpg">
<meta property="og:image" content="http://chant00.com/media/15047848212089.jpg">
<meta property="og:image" content="http://chant00.com/media/15047859314343.jpg">
<meta property="og:image" content="http://chant00.com/media/2-1.png">
<meta property="og:image" content="http://chant00.com/media/15047877612658.jpg">
<meta property="og:image" content="http://chant00.com/media/15047888584939.jpg">
<meta property="og:image" content="http://chant00.com/media/15047889247578.jpg">
<meta property="og:image" content="http://chant00.com/media/15047889425546.jpg">
<meta property="og:image" content="http://chant00.com/media/15047889833790.jpg">
<meta property="og:image" content="http://chant00.com/media/3-1.png">
<meta property="og:image" content="http://chant00.com/media/4.png">
<meta property="og:image" content="http://chant00.com/media/15048008791736.jpg">
<meta property="og:image" content="http://chant00.com/media/15048023651096.jpg">
<meta property="og:image" content="http://chant00.com/media/15048024141264.jpg">
<meta property="og:image" content="http://chant00.com/media/15048024797603.jpg">
<meta property="og:image" content="http://chant00.com/media/15048025267839.jpg">
<meta property="og:image" content="http://chant00.com/media/15048025515448.jpg">
<meta property="og:image" content="http://chant00.com/media/15048025737557.jpg">
<meta property="og:updated_time" content="2017-09-08T14:35:45.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HADOOP--hadoop运行原理及其搭建">
<meta name="twitter:description" content="hadoop从运行机制到搭建，加网上常见的天气、好友推荐及协同过滤案列的实践。">
<meta name="twitter:image" content="http://chant00.com/media/15047669347861.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://chant00.com/2016/11/08/HADOOP--hadoop运行原理及其搭建/"/>





  <title>HADOOP--hadoop运行原理及其搭建 | Chant</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?20a728b896cddba838b0448e60f910f5";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>











  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Chant</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Take things as they are with a cavalier attitude./用漫不经心的态度过随遇而安的生活</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-favourite">
          <a href="/favourite" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            颜如玉
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://chant00.com/2016/11/08/HADOOP--hadoop运行原理及其搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chant">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chant">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">HADOOP--hadoop运行原理及其搭建</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-11-08T08:47:49+08:00">
                2016-11-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2016/11/08/HADOOP--hadoop运行原理及其搭建/" class="leancloud_visitors" data-flag-title="HADOOP--hadoop运行原理及其搭建">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <script src="/assets/js/DPlayer.min.js"> </script><script src="/assets/js/APlayer.min.js"> </script><p>hadoop从运行机制到搭建，加网上常见的天气、好友推荐及协同过滤案列的实践。</p>
<a id="more"></a>
<h3 id="Hadoop的三大核心模块"><a href="#Hadoop的三大核心模块" class="headerlink" title="Hadoop的三大核心模块"></a>Hadoop的三大核心模块</h3><p>分布式存储系统HDFS（Hadoop Distributed File System），提供了高可靠性、高扩展性和高吞吐率的数据存储服务；<br>分布式计算框架MapReduce，具有易于编程、高容错性和高扩展性等优点；<br>分布式资源管理框架YARN（Yet Another Resource Management），负责集群资源的管理和调度。<br>Hadoop的生态系统中包含多种技术：比如Hive、Hbase、Spark等。</p>
<h3 id="分布式存储系统HDFS"><a href="#分布式存储系统HDFS" class="headerlink" title="分布式存储系统HDFS"></a>分布式存储系统HDFS</h3><h4 id="存储模型"><a href="#存储模型" class="headerlink" title="存储模型"></a>存储模型</h4><ul>
<li>文件线性切割成块（Block）：大文件切分为小文件</li>
<li>偏移量offset（byte）：每一个块的起始位置相对于原始文件的字节索引</li>
<li>Block分散存储在集群节点中，单一文件Block大小一致，文件与文件之间Block大小可以不一致，Block可以设置副本数，副本分散在不同节点中，副本数不要超过节点数量，文件上传可以设置Block大小和副本数，已上传的文件Block副本数可以调整，大小不变</li>
<li>只支持一次写入多次读取（修改是泛洪操作，集群开销很大，所有不允许在块中增删改操作），同一时刻只有一个写入者</li>
<li>可以append追加数据（加块，单点操作）</li>
</ul>
<h4 id="架构模型"><a href="#架构模型" class="headerlink" title="架构模型"></a>架构模型</h4><p>概念：文件元数据MetaData，文件数据<br>元数据：理解为文件的属性，比如权限、修改日期，文件名等<br>数据本身：理解为文件中的内容<br>NameNode节点（主）保存文件元数据：单节点   posix<br>DataNode节点（从）保存文件Block数据：多节点<br>DataNode与NameNode保持心跳，提交Block列表<br>HdfsClient与NameNode交互元数据信息<br>HdfsClient与DataNode交互文件Block数据<br>HDFS架构<br><img src="/media/15047669347861.jpg" alt=""><br>HDFS设计思想<br><img src="/media/15047669465372.jpg" alt=""></p>
<h4 id="NameNode（NN）"><a href="#NameNode（NN）" class="headerlink" title="NameNode（NN）"></a>NameNode（NN）</h4><p>基于内存存储，不会和磁盘发生交换，只存在内存中，但也有持久化的功能，只是单方向的存储，防止断电丢失，不会发生内存和磁盘的交换，NameNode的metadate信息在启动后会加载到内存，metadata存储到磁盘文件名为”fsimage”，Block的位置信息不会保存到fsimage，由DataNode汇报，“edits”记录对metadata的操作日志。<br>NameNode主要功能：<br>接受客户端的读写服务，收集DataNode汇报的Block列表信息，NameNode保存metadata信息包括：文件owership、permissions、文件大小、时间、Block列表、Block偏移量和位置信息（副本位置由DataNode汇报，实时改变，不会持久化）等。</p>
<h4 id="DataNode（DN）"><a href="#DataNode（DN）" class="headerlink" title="DataNode（DN）"></a>DataNode（DN）</h4><p>使用本地磁盘目录以文件形式存储数据（Block），同时存储Block的元数据信息文件（校验和，用于检测数据块是否损坏），启动DN时会向NN汇报block信息，通过向NN发送心跳保持与其联系（3秒一次），如果NN 10分钟没有收到DN的心跳，则认为其已经lost，并copy其上的block到其它DN。</p>
<h4 id="SecondaryNameNode（SNN）"><a href="#SecondaryNameNode（SNN）" class="headerlink" title="SecondaryNameNode（SNN）"></a>SecondaryNameNode（SNN）</h4><p>它不是NN的备份（但可以做备份），它的主要工作是帮助NN合并edits log，减少NN启动时间。SNN执行合并时机：根据配置文件设置的时间间隔fs.checkpoint.period，默认3600秒或者根据配置文件设置edits log大小fs.checkpoint.size规定edits文件的最大值，默认是64MB。<br>SNN在hadoop2.0后就不再使用。<br>SNN合并流程：<br><img src="/media/15047669842275.jpg" alt=""></p>
<ol>
<li>NN创建一个新的edits log来接替老的edits的工作 </li>
<li>NN将fsimage和旧的edits拷备到SNN上</li>
<li>SNN上进行合并操作，产生一个新的fsimage</li>
<li>将新的fsimage复制一份到NN上</li>
<li>使用新的fsimage和新的edits log</li>
</ol>
<h4 id="Block的副本放置策略"><a href="#Block的副本放置策略" class="headerlink" title="Block的副本放置策略"></a>Block的副本放置策略</h4><p><img src="/media/15047670576624.jpg" alt=""><br>第一个副本：放置在上传文件的DN；如果是集群外提交，则随机挑选一台磁盘不太满，CPU不太忙的节点。<br>第二个副本：放置在于第一个副本不同的机架的节点上。<br>第三个副本：与第二个副本相同机架的节点。<br>更多副本：随机节点。<br>HDFS写流程<br>下图描述的是上传一个block的流程：<br><img src="/media/15047670965346.jpg" alt=""></p>
<ol>
<li>客户端创建DistributedFileSystem对象.</li>
<li>DistributedFileSystem对象调用元数据节点，在文件系统的命名空间中创建一个新的文件，元数据节点首先确定文件原来不存在，并且客户端有创建文件的权限，然后创建新文件，并标识为“上传中”状态，即可以看见，但不能使用。</li>
<li>DistributedFileSystem返回DFSOutputStream，客户端用于写数据。</li>
<li>客户端开始写入数据，DFSOutputStream将数据分成块，写入data queue（Data queue由Data Streamer读取），并通知元数据节点分配数据节点，用来存储数据块（每块默认复制3块）。分配的数据节点放在一个pipeline里。Data Streamer将数据块写入pipeline中的第一个数据节点。第一个数据节点将数据块发送给第二个数据节点。第二个数据节点将数据发送给第三个数据节点。注意：并不是第一个数据节点完全接收完block后再发送给后面的数据节点，而是接收到一部分就发送，所以三个节点几乎是同时接收到完整的block的。DFSOutputStream为发出去的数据块保存了ack queue，等待pipeline中的数据节点告知数据已经写入成功。如果block在某个节点的写入的过程中失败：关闭pipeline，将ack queue放至data queue的开始。已经写入节点中的那些block部分会被元数据节点赋予新的标示，发生错误的节点重启后能够察觉其数据块是过时的，会被删除。失败的节点从pipeline中移除，block的其他副本则写入pipeline中的另外两个数据节点。元数据节点则被通知此block的副本不足，将来会再创建第三份备份。</li>
<li>ack queue返回成功。</li>
<li>客户端结束写入数据，则调用stream的close函数，最后通知元数据节点写入完毕</li>
</ol>
<p>总结：<br>    客户端切分文件Block，按Block线性地和NN获取DN列表（副本数），验证DN列表后以更小的单位流式传输数据，各节点两两通信确定可用，Block传输结束后，DN向NN汇报Block信息，DN向Client汇报完成，Client向NN汇报完成，获取下一个Block存放的DN列表，最终Client汇报完成，NN会在写流程更新文件状态。</p>
<h4 id="HDFS读流程"><a href="#HDFS读流程" class="headerlink" title="HDFS读流程"></a>HDFS读流程</h4><p><img src="/media/15047671569429.jpg" alt=""></p>
<ol>
<li>客户端(client)用FileSystem的open()函数打开文件。</li>
<li>DistributedFileSystem调用元数据节点，得到文件的数据块信息。对于每一个数据块，元数据节点返回保存数据块的数据节点的地址。</li>
<li>DistributedFileSystem返回FSDataInputStream给客户端，用来读取数据。</li>
<li>客户端调用stream的read()函数开始读取数据（也会读取block的元数据）。DFSInputStream连接保存此文件第一个数据块的最近的数据节点（优先读取同机架的block）。</li>
<li>Data从数据节点读到客户端。当此数据块读取完毕时，DFSInputStream关闭和此数据节点的连接，然后连接此文件下一个数据块的最近的数据节点。</li>
<li>当客户端读取完毕数据的时候，调用FSDataInputStream的close函数。</li>
<li>在读取数据的过程中，如果客户端在与数据节点通信出现错误，则尝试连接包含此数据块的下一个数据节点。失败的数据节点将被记录，以后不再连接。</li>
</ol>
<p>总结：<br>客户端和NN获取一部分Block（获取部分block信息，而不是整个文件全部的block信息，读完这部分block后，再获取另一个部分block的信息）副本位置列表，线性地和DN获取Block，最终合并为一个文件，在Block副本列表中按距离择优选取。</p>
<h4 id="安全模式"><a href="#安全模式" class="headerlink" title="安全模式"></a>安全模式</h4><p>namenode启动的时候，首先将映像文件(fsimage)载入内存，并执行编辑日志(edits)中的各项操作。一旦在内存中成功建立文件系统元数据的映射，则创建一个新的fsimage文件（这个操作不需要SecondaryNameNode）和一个空的编辑日志。此刻namenode运行在安全模式。即namenode的文件系统对于客服端来说是只读的（显示目录，显示文件内容等。写、删除、重命名都会失败）。在此阶段Namenode收集各个datanode的报告，当数据块达到最小副本数以上时，会被认为是“安全”的， 在一定比例（可设置）的数据块被确定为“安全”后，再过若干时间，安全模式结束。当检测到副本数不足的数据块时，该块会被复制直到达到最小副本数，系统中数据块的位置并不是由namenode维护的，而是以块列表形式存储在datanode中。</p>
<h4 id="HDFS优点"><a href="#HDFS优点" class="headerlink" title="HDFS优点"></a>HDFS优点</h4><ul>
<li>高容错性<br>数据自动保存多个副本，副本丢失后，自动恢复</li>
<li>适合批处理<br>移动计算而非数据，数据位置暴露给计算框架（Block偏移量）</li>
<li>适合大数据处理<br>GB 、TB 、甚至PB 级数据，百万规模以上的文件数量，10K+节点数量</li>
<li>可构建在廉价机器上<br>通过多副本提高可靠性，提供了容错和恢复机制</li>
</ul>
<h4 id="HDFS缺点"><a href="#HDFS缺点" class="headerlink" title="HDFS缺点"></a>HDFS缺点</h4><ul>
<li>低延迟数据访问<br>HDFS不太适合于那些要求低延时（数十毫秒）访问的应用程序，因为HDFS是设计用于大吞吐量数据的，这是以一定延时为代价的。HDFS是单Master的，所有对文件的请求都要经过它，当请求多时，肯定会有延时。</li>
<li>小文件存取时占用NameNode 大量内存，寻道时间超过读取时间</li>
<li>一个文件只能有一个写者，且仅支持append</li>
</ul>
<h3 id="Pseudo-Distributed-Mode安装配置"><a href="#Pseudo-Distributed-Mode安装配置" class="headerlink" title="Pseudo-Distributed Mode安装配置"></a>Pseudo-Distributed Mode安装配置</h3><h6 id="1-安装配置JDK"><a href="#1-安装配置JDK" class="headerlink" title="1.    安装配置JDK"></a>1.    安装配置JDK</h6><h6 id="2-解压hadoop-2-6-5-tar-gz"><a href="#2-解压hadoop-2-6-5-tar-gz" class="headerlink" title="2.    解压hadoop-2.6.5.tar.gz"></a>2.    解压hadoop-2.6.5.tar.gz</h6><p>[root@node01 software]# tar xf hadoop-2.6.5.tar.gz<br>[root@node01 software]# mv hadoop-2.6.5 /opt/sxt/</p>
<h6 id="3-在环境变量中加入hadoop安装路径"><a href="#3-在环境变量中加入hadoop安装路径" class="headerlink" title="3.    在环境变量中加入hadoop安装路径"></a>3.    在环境变量中加入hadoop安装路径</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node01 hadoop-2.6.5]# vi /etc/profile</div><div class="line">export HADOOP_PREFIX=/opt/sxt/hadoop-2.6.5</div><div class="line">export PATH=$JAVA_HOME/bin:$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin</div><div class="line">[root@node01 hadoop-2.6.5]# . /etc/profile</div></pre></td></tr></table></figure>
<h6 id="4-设置ssh登录本机免秘钥"><a href="#4-设置ssh登录本机免秘钥" class="headerlink" title="4.    设置ssh登录本机免秘钥"></a>4.    设置ssh登录本机免秘钥</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[root@node01 ~]# ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa</div><div class="line">#生成了.ssh目录</div><div class="line">[root@node01 ~]# ll -a</div><div class="line">drwx------   2 root root  4096 7月   4 12:53 .ssh</div><div class="line">[root@node01 ~]# cd .ssh</div><div class="line">[root@node01 .ssh]# ll</div><div class="line">总用量 12</div><div class="line">-rw------- 1 root root 672 7月   4 12:53 id_dsa #私钥</div><div class="line">-rw-r--r-- 1 root root 601 7月   4 12:53 id_dsa.pub #公钥</div><div class="line">-rw-r--r-- 1 root root 802 7月   3 20:47 known_hosts</div><div class="line">#想登陆哪台机器，就把公钥copy给哪台机器，登陆自身免密执行如下命令</div><div class="line">[root@node01 .ssh]# cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</div></pre></td></tr></table></figure>
<h6 id="5-修改hadoop配置文件-env-sh"><a href="#5-修改hadoop配置文件-env-sh" class="headerlink" title="5.    修改hadoop配置文件-env.sh"></a>5.    修改hadoop配置文件-env.sh</h6><p>在-env.sh文件中配置JAVA_HOME，因为在远程调用时，不会读取/etc/profile文件，所以取不到JAVA_HOME<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node01 hadoop]# cd /opt/sxt/hadoop-2.6.5/etc/hadoop/</div><div class="line">#以下3个文件中加入JAVA_HOME</div><div class="line">[root@node01 hadoop]# vi hadoop-env.sh</div><div class="line">[root@node01 hadoop]# vi mapred-env.sh </div><div class="line">[root@node01 hadoop]# vi yarn-env.sh</div><div class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67</div></pre></td></tr></table></figure></p>
<h6 id="6-修改hadoop配置文件，配置伪分布式相关的内容"><a href="#6-修改hadoop配置文件，配置伪分布式相关的内容" class="headerlink" title="6.    修改hadoop配置文件，配置伪分布式相关的内容"></a>6.    修改hadoop配置文件，配置伪分布式相关的内容</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">[root@node01 hadoop]# vi core-site.xml</div><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;!--设置namenode所在节点--&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">        &lt;value&gt;hdfs://node01:9000&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;!--设置hadoop存放数据的临时目录--&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">    &lt;value&gt;/var/sxt/hadoop/pseudo&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div><div class="line">[root@node01 hadoop]# vi hdfs-site.xml</div><div class="line">&lt;configuration&gt;</div><div class="line">&lt;!--设置副本数，不能超过节点数--&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">        &lt;value&gt;1&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;!—设置secondaryNode在哪个节点--&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">    &lt;value&gt;node01:50090&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>说明：<br>Hadoop默认把数据块的元数据和数据存放在操作系统的/tmp目录下，但操作系统的/tmp目录会定期清空，所以要做修改</p>
<table>
<thead>
<tr>
<th>name</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>hadoop.tmp.dir</td>
<td>/tmp/hadoop-${user.name}</td>
</tr>
<tr>
<td>dfs.namenode.name.dir</td>
<td>file://${hadoop.tmp.dir}/dfs/name</td>
</tr>
<tr>
<td>dfs.datanode.data.dir</td>
<td>file://${hadoop.tmp.dir}/dfs/data</td>
</tr>
</tbody>
</table>
<h6 id="7-设置datanode在哪些节点"><a href="#7-设置datanode在哪些节点" class="headerlink" title="7.    设置datanode在哪些节点"></a>7.    设置datanode在哪些节点</h6><p><code>[root@node01 hadoop]# vi slaves</code><br><code>node01</code></p>
<h6 id="8-格式化文件系统"><a href="#8-格式化文件系统" class="headerlink" title="8.    格式化文件系统"></a>8.    格式化文件系统</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">[root@node01 hadoop]# hdfs namenode –format</div><div class="line">#成功信息：</div><div class="line">Storage directory /var/sxt/hadoop/pseudo/dfs/name has been successfully formatted.</div><div class="line">[root@node01 hadoop]# cd /var/sxt/hadoop/pseudo/dfs/name/current</div><div class="line">[root@node01 current]# ll</div><div class="line">总用量 16</div><div class="line">-rw-r--r-- 1 root root 320 7月   4 13:36 fsimage_0000000000000000000</div><div class="line">-rw-r--r-- 1 root root  62 7月   4 13:36 fsimage_0000000000000000000.md5</div><div class="line">-rw-r--r-- 1 root root   2 7月   4 13:36 seen_txid</div><div class="line">-rw-r--r-- 1 root root 204 7月   4 13:36 VERSION</div><div class="line">[root@node01 current]# vi VERSION</div><div class="line">#Tue Jul 04 13:36:11 CST 2017</div><div class="line">namespaceID=160288852</div><div class="line">clusterID=CID-e2d83b00-0c46-45b2-9f86-e824c42795e8 #集群的ID</div><div class="line">cTime=0</div><div class="line">storageType=NAME_NODE</div><div class="line">blockpoolID=BP-1597373193-192.168.9.11-1499146571542</div><div class="line">layoutVersion=-60</div></pre></td></tr></table></figure>
<h6 id="9-启动hdfs系统"><a href="#9-启动hdfs系统" class="headerlink" title="9.    启动hdfs系统"></a>9.    启动hdfs系统</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node01 current]# start-dfs.sh</div><div class="line">Starting namenodes on [node01]</div><div class="line">node01: starting namenode, logging to /opt/sxt/hadoop-2.6.5/logs/hadoop-root-namenode-node01.out</div><div class="line">node01: starting datanode, logging to /opt/sxt/hadoop-2.6.5/logs/hadoop-root-datanode-node01.out</div><div class="line">Starting secondary namenodes [node01]</div><div class="line">node01: starting secondarynamenode, logging to /opt/sxt/hadoop-2.6.5/logs/hadoop-root-secondarynamenode-node01.out</div></pre></td></tr></table></figure>
<h6 id="10-查看进程是否启动"><a href="#10-查看进程是否启动" class="headerlink" title="10.    查看进程是否启动"></a>10.    查看进程是否启动</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node01 current]# jps</div><div class="line">3375 SecondaryNameNode</div><div class="line">3241 DataNode</div><div class="line">3481 Jps</div><div class="line">3136 NameNode</div></pre></td></tr></table></figure>
<p>说明：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[root@node01 current]# cd /var/sxt/hadoop/pseudo/dfs/data/current</div><div class="line">[root@node01 current]# vi VERSION</div><div class="line">#Tue Jul 04 13:42:12 CST 2017</div><div class="line">storageID=DS-4fd6b46c-6567-4875-9dcf-17577873d372</div><div class="line">#与name下的VERSION中的clusterID相同，否则NN与DN不会通信</div><div class="line">clusterID=CID-e2d83b00-0c46-45b2-9f86-e824c42795e8 </div><div class="line">cTime=0</div><div class="line">datanodeUuid=e18d8595-35b6-40b3-9dde-abc56f90c77b</div><div class="line">storageType=DATA_NODE</div><div class="line">layoutVersion=-56</div></pre></td></tr></table></figure></p>
<h6 id="11-去网页验证"><a href="#11-去网页验证" class="headerlink" title="11.去网页验证"></a>11.去网页验证</h6><p><img src="/media/15047677025181.jpg" alt=""></p>
<h4 id="HDFS的基本操作"><a href="#HDFS的基本操作" class="headerlink" title="HDFS的基本操作"></a>HDFS的基本操作</h4><p>刚创建好文件系统后，只是一个空系统，存放数据的目录为空<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node01 ~]# cd /var/sxt/hadoop/pseudo/dfs/data/current/BP-1597373193-192.168.9.11-1499146571542/current/finalized</div><div class="line">[root@node01 finalized]# ll</div><div class="line">总用量 0</div></pre></td></tr></table></figure></p>
<h6 id="1-创建目录："><a href="#1-创建目录：" class="headerlink" title="1.创建目录："></a>1.创建目录：</h6><p><code>[root@node01 finalized]# hdfs dfs -mkdir -p /user/root</code><br><img src="/media/15047678033762.jpg" alt=""><br><img src="/media/15047678133842.jpg" alt=""></p>
<h6 id="2-上传文件："><a href="#2-上传文件：" class="headerlink" title="2.上传文件："></a>2.上传文件：</h6><p><code>[root@node01 finalized]# hdfs dfs -put /etc/profile /user/root</code><br><img src="/media/15047678410192.jpg" alt=""><br>在finalized目录下新增了subdir0目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">[root@node01 finalized]# ll</div><div class="line">总用量 4</div><div class="line">drwxr-xr-x 3 root root 4096 7月   4 14:01 subdir0</div><div class="line">[root@node01 finalized]# cd subdir0/</div><div class="line">[root@node01 subdir0]# ll</div><div class="line">总用量 4</div><div class="line">drwxr-xr-x 2 root root 4096 7月   4 14:01 subdir0</div><div class="line">[root@node01 subdir0]# cd subdir0/</div><div class="line">[root@node01 subdir0]# ll</div><div class="line">总用量 8</div><div class="line">-rw-r--r-- 1 root root 1950 7月   4 14:01 blk_1073741825</div><div class="line">-rw-r--r-- 1 root root   23 7月   4 14:01 blk_1073741825_1001.meta</div><div class="line">[root@node01 subdir0]# cat blk_1073741825</div><div class="line"># /etc/profile</div><div class="line">……</div><div class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67</div><div class="line">export HADOOP_PREFIX=/opt/sxt/hadoop-2.6.5</div><div class="line">export PATH=$JAVA_HOME/bin:$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin</div><div class="line">……</div></pre></td></tr></table></figure></p>
<p>blk_1073741825文件就是刚才上传的/etc/profile文件</p>
<h6 id="3-上传文件时指定块大小为1M"><a href="#3-上传文件时指定块大小为1M" class="headerlink" title="3.上传文件时指定块大小为1M"></a>3.上传文件时指定块大小为1M</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node01 ~]# hdfs dfs -D dfs.blocksize=1048576 -put /usr/local/software/hadoop-2.6.5.t</div><div class="line">ar.gz #不写目标目录，就会上传到当前用户家目录，即/user/root，前提是该目录存在</div></pre></td></tr></table></figure>
<p><img src="/media/15047678977458.jpg" alt=""><br><img src="/media/15047679401077.jpg" alt=""></p>
<h4 id="Fully-Distributed-Mode安装配置"><a href="#Fully-Distributed-Mode安装配置" class="headerlink" title="Fully-Distributed Mode安装配置"></a>Fully-Distributed Mode安装配置</h4><h6 id="角色划分"><a href="#角色划分" class="headerlink" title="角色划分"></a>角色划分</h6><table>
<thead>
<tr>
<th></th>
<th>NN</th>
<th>SNN</th>
<th>DN</th>
</tr>
</thead>
<tbody>
<tr>
<td>node01</td>
<td>√</td>
<td></td>
<td></td>
</tr>
<tr>
<td>node02</td>
<td></td>
<td>√</td>
<td>√ </td>
</tr>
<tr>
<td>node03</td>
<td></td>
<td></td>
<td>√  </td>
</tr>
<tr>
<td>node04</td>
<td></td>
<td></td>
<td>√</td>
</tr>
</tbody>
</table>
<p>补充：使用集群的时候要保证每台服务器的系统时间一致，使用data查看系统时间，data -s “yyyy-mm-dd hh:mm:ss”格式的命令修改系统时间。</p>
<h6 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h6><pre><code>如果有别的hdfs进程在运行，先停掉，比如停掉之前的伪分布式系统
</code></pre><p>[root@node01 ~]# stop-dfs.sh</p>
<h6 id="1-在每台node上安装jdk并配置环境变量"><a href="#1-在每台node上安装jdk并配置环境变量" class="headerlink" title="1.在每台node上安装jdk并配置环境变量"></a>1.在每台node上安装jdk并配置环境变量</h6><h6 id="2-配置免秘钥登录"><a href="#2-配置免秘钥登录" class="headerlink" title="2.配置免秘钥登录"></a>2.配置免秘钥登录</h6><p>使用node02、node03、node04使用ssh登录本机再退出，目的是让它们创建.ssh目录及known_hosts文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">#把node01的公钥copy到其他节点</div><div class="line">[root@node01 .ssh]# scp ./id_dsa.pub node02:/root/node01.pub</div><div class="line">[root@node01 .ssh]# scp ./id_dsa.pub node03:/root/node01.pub</div><div class="line">[root@node01 .ssh]# scp ./id_dsa.pub node04:/root/node01.pub</div><div class="line">#把node0&#123;2,3,4&#125;中的node01公钥内容copy到各自的authorized_keys文件中</div><div class="line">[root@node02 ~]# cat ~/node01.pub &gt;&gt; ~/.ssh/authorized_keys</div><div class="line">[root@node03 ~]# cat ~/node01.pub &gt;&gt; ~/.ssh/authorized_keys</div><div class="line">[root@node04 ~]# cat ~/node01.pub &gt;&gt; ~/.ssh/authorized_keys</div></pre></td></tr></table></figure></p>
<h6 id="3-在node01中对hadoop的配置文件做修改"><a href="#3-在node01中对hadoop的配置文件做修改" class="headerlink" title="3.    在node01中对hadoop的配置文件做修改"></a>3.    在node01中对hadoop的配置文件做修改</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">[root@node01 ~r# cd /opt/sxt/hadoop-2.6.5/etc</div><div class="line">#将hadoop文件夹copy为hadoop-pseudo，hdfs默认会找hadoop目录中的配置文件</div><div class="line">[root@node01 etc]# cp -r hadoop hadoop-pseudo</div><div class="line">[root@node01 etc]# cd hadoop</div><div class="line">#如有必要，在-env.sh文件中配置JAVA_HOME</div><div class="line">[root@node01 hadoop]# vi core-site.xml</div><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">        &lt;value&gt;hdfs://node01:9000&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;!—数据临时存放目录最好设置为空目录--&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">        &lt;value&gt;/var/sxt/hadoop/full&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div><div class="line">[root@node01 hadoop]# vi hdfs-site.xml</div><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">        &lt;value&gt;2&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">        &lt;value&gt;node02:50090&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div><div class="line">[root@node01 hadoop]# vi slaves</div><div class="line">node02</div><div class="line">node03</div><div class="line">node04</div></pre></td></tr></table></figure>
<h6 id="4-将node01的hadoop安装目录分发给其他节点"><a href="#4-将node01的hadoop安装目录分发给其他节点" class="headerlink" title="4.将node01的hadoop安装目录分发给其他节点"></a>4.将node01的hadoop安装目录分发给其他节点</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node01 sxt]# scp -r hadoop-2.6.5 node02:`pwd`</div><div class="line">[root@node01 sxt]# scp -r hadoop-2.6.5 node03:`pwd`</div><div class="line">[root@node01 sxt]# scp -r hadoop-2.6.5 node04:`pwd`</div></pre></td></tr></table></figure>
<h6 id="5-格式化文件系统（只在第一次启动时格式化）"><a href="#5-格式化文件系统（只在第一次启动时格式化）" class="headerlink" title="5.格式化文件系统（只在第一次启动时格式化）"></a>5.格式化文件系统（只在第一次启动时格式化）</h6><p><code>[root@node01 sxt]# hdfs namenode -format</code></p>
<h6 id="6-启动服务"><a href="#6-启动服务" class="headerlink" title="6.启动服务"></a>6.启动服务</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@node01 sxt]# start-dfs.sh</div><div class="line">Starting namenodes on [node01]</div><div class="line">node01: starting namenode, logging to /opt/sxt/hadoop-2.6.5/logs/hadoop-root-namenode-node01.out</div><div class="line">node04: starting datanode, logging to /opt/sxt/hadoop-2.6.5/logs/hadoop-root-datanode-node04.out</div><div class="line">node02: starting datanode, logging to /opt/sxt/hadoop-2.6.5/logs/hadoop-root-datanode-node02.out</div><div class="line">node03: starting datanode, logging to /opt/sxt/hadoop-2.6.5/logs/hadoop-root-datanode-node03.out</div><div class="line">Starting secondary namenodes [node02]</div><div class="line">node02: starting secondarynamenode, logging to /opt/sxt/hadoop-2.6.5/logs/hadoop-root-secondarynamenode-node02.out</div></pre></td></tr></table></figure>
<p><img src="/media/15047684860948.jpg" alt=""></p>
<h6 id="7-进行一些操作"><a href="#7-进行一些操作" class="headerlink" title="7.进行一些操作"></a>7.进行一些操作</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node01 ~]# for i in `seq 100000`;do echo &quot;$i Hello sxt You Are Good&quot; &gt;&gt;</div><div class="line">/tmp/hello.txt;done</div><div class="line">[root@node01 ~]# hdfs dfs -D dfs.blocksize=1048576 -put /tmp/hello.txt</div><div class="line">#hdfs切割文件时，按照字节来切分，思考，如果是中文，怎么切割？</div></pre></td></tr></table></figure>
<p><img src="/media/15047685351341.jpg" alt=""><br>去node02上查看Block1<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@node02 ~]# cd /var/sxt/hadoop/full/dfs/data/current/BP-362752143-192.168.9.11-1499153025245/current/finalized/subdir0/subdir0</div><div class="line">[root@node02 subdir0]# vi blk_1073741826</div><div class="line">e Good</div><div class="line">36542 Hello sxt You Are Good</div><div class="line">……</div><div class="line">72698 Hello sxt You Are Good</div><div class="line">72699 Hello sxt</div></pre></td></tr></table></figure></p>
<h3 id="Hadoop-2-0"><a href="#Hadoop-2-0" class="headerlink" title="Hadoop 2.0"></a>Hadoop 2.0</h3><h4 id="产生背景"><a href="#产生背景" class="headerlink" title="产生背景"></a>产生背景</h4><p>Hadoop 1.0中HDFS和MapReduce在高可用、扩展性等方面存在问题<br>HDFS存在的问题：<br>NameNode单点故障，难以应用于在线场景<br>NameNode压力过大，且内存受限，影响系统扩展性<br>MapReduce存在的问题：<br>JobTracker访问压力大，影响系统扩展性<br>难以支持除MapReduce之外的计算框架，比如Spark、Storm等</p>
<h4 id="Hadoop-1-0和2-0架构比较"><a href="#Hadoop-1-0和2-0架构比较" class="headerlink" title="Hadoop 1.0和2.0架构比较"></a>Hadoop 1.0和2.0架构比较</h4><p><img src="/media/15047686581032.jpg" alt=""></p>
<blockquote>
<p>Hadoop 2.x由HDFS、MapReduce和YARN三个分支构成。<br>HDFS：NN Federation（联邦）、HA（只支持2个节点，3.0实现了一主多从）。<br>MapReduce：运行在YARN上的MR；离线计算，基于磁盘I/O计算。<br>YARN：资源管理系统。</p>
</blockquote>
<h4 id="HDFS-2-x"><a href="#HDFS-2-x" class="headerlink" title="HDFS 2.x"></a>HDFS 2.x</h4><p>HDFS 2.x解决HDFS 1.0中单点故障和内存受限问题。<br>解决单点故障：<br>HDFS HA：通过主备NameNode解决，如果主NameNode发生故障，则切换到备NameNode上。<br>解决内存受限问题：<br>HDFS Federation（联邦）水平扩展，支持多个NameNode。每个NameNode分管一部分目录，所有NameNode共享所有DataNode存储资源。<br>2.x仅是架构上发生了变化，使用方式不变，对HDFS使用者透明，HDFS 1.x中的命令和API仍可以使用。</p>
<h4 id="HDFS-2-x-Federation"><a href="#HDFS-2-x-Federation" class="headerlink" title="HDFS 2.x Federation"></a>HDFS 2.x Federation</h4><p>通过多个namenode/namespace把元数据的存储和管理分散到多个节点中，使到namenode/namespace可以通过增加机器来进行水平扩展。能把单个namenode的负载分散到多个节点中，在HDFS数据规模较大的时候不会也降低HDFS的性能。可以通过多个namespace来隔离不同类型的应用，把不同类型应用的HDFS元数据的存储和管理分派到不同的namenode中。核心：多台namenode管理的是同一个集群！<br><img src="/media/15047688486656.jpg" alt=""></p>
<h4 id="HDFS-2-x-HA（High-Availability）"><a href="#HDFS-2-x-HA（High-Availability）" class="headerlink" title="HDFS 2.x HA（High Availability）"></a>HDFS 2.x HA（High Availability）</h4><p><img src="/media/15047688732629.jpg" alt=""><br>主备NameNode，解决单点故障：<br>ANN：ActiveNameNode，对外提供服务，SNN同步ANN元数据，以待切换。<br>SNN：StandbyNameNode，完成了edits.log文件的合并产生新的image，推送回ANN。<br>JNN：JournalNode，ANN和SNN通过JNN集群来共享信息。两个NameNode为了数据同步，会通过一组称作JournalNodes的独立进程进行相互通信。当ANN的命名空间有任何修改时，会告知大部分的JournalNodes进程。SNN有能力读取JNs中的变更信息，并且一直监控edit log的变化，把变化应用于自己的命名空间。SNN可以确保在集群出错时，命名空间状态已经完全同步了。在HA架构里面SecondaryNameNode这个冷备角色已经不存在了，为了保持SNN实时的与ANN的元数据保持一致，他们之间交互通过一系列守护的轻量级进程JournalNode。基本原理就是用2N+1台JN存储editlog，每次写数据操作有超过半数（&gt;=N+1）返回成功时即认为该次写成功，数据不会丢失了。当然这个算法所能容忍的是最多有N台机器挂掉，如果多于N台挂掉，这个算法就失效了。任何修改操作在ANN上执行时，JN进程同时也会记录修改log到至少半数以上的JN中，这时SNN监测到JN里面的同步log发生变化了会读取JN里面的修改log，然后同步到自己的的目录镜像树里面。当发生故障时，ANN挂掉后，SNN会在它成为ANN前，读取所有的JN里面的修改日志，这样就能高可靠的保证与挂掉的NN的目录镜像树一致，然后无缝的接替它的职责，维护来自客户端请求，从而达到一个高可用的目的。<br>DN：同时向两个NameNode汇报数据块信息（位置）。<br>两个NN之间的切换：<br>手动切换：通过命令实现主备之间的切换，可以用HDFS升级等场合。<br>自动切换：基于Zookeeper实现。<br>HDFS 2.x提供了ZookeeperFailoverController角色，部署在每个NameNode的节点上，作为一个deamon进程, 简称zkfc，zkfc主要包括三个组件：<br>HealthMonitor：监控NameNode是否处于unavailable或unhealthy状态。当前通过RPC调用NN相应的方法完成。<br>ActiveStandbyElector：管理和监控自己在ZK中的状态。<br>ZKFailoverController：它订阅HealthMonitor和ActiveStandbyElector的事件，并管理NameNode的状态。<br>ZKFailoverController主要职责：</p>
<ul>
<li>健康监测：周期性的向它监控的NN发送健康探测命令，从而来确定某个NameNode是否处于健康状态，如果机器宕机，心跳失败，那么zkfc就会标记它处于一个不健康的状态</li>
<li>记它会话管理：如果NN是健康的，zkfc就会在zookeeper中保持一个打开的会话，如果NameNode同时还是Active状态的，那么zkfc还会在Zookeeper中占有一个类型为短暂类型的znode，当这个NN挂掉时，这个znode将会被删除，然后备用的NN，将会得到这把锁，升级为主NN，同时标记状态为Active，当宕机的NN新启动时，它会再次注册zookeper，发现已经有znode锁了，便会自动变为Standby状态，如此往复循环，保证高可靠，需要注意，目前仅仅支持最多配置2个NN.</li>
<li>master选举：如上所述，通过在zookeeper中维持一个短暂类型的znode，来实现抢占式的锁机制，从而判断那个NameNode为Active状态。</li>
</ul>
<h4 id="HDFS-2-x-HA-搭建"><a href="#HDFS-2-x-HA-搭建" class="headerlink" title="HDFS 2.x HA 搭建"></a>HDFS 2.x HA 搭建</h4><p>角色划分<br><img src="/media/15047696336748.jpg" alt=""><br>步骤：</p>
<h6 id="1-在node02上解压zookeeper包"><a href="#1-在node02上解压zookeeper包" class="headerlink" title="1.在node02上解压zookeeper包"></a>1.在node02上解压zookeeper包</h6><p><code>[root@node02 software]# tar xf zookeeper-3.4.6.tar.gz</code><br><code>[root@node02 ###### [root@node02 software]# mv zookeeper-3.4.6 /opt/sxt/</code></p>
<h6 id="2-修改-etc-profile文件，配置zookeeper路径"><a href="#2-修改-etc-profile文件，配置zookeeper路径" class="headerlink" title="2.修改/etc/profile文件，配置zookeeper路径"></a>2.修改/etc/profile文件，配置zookeeper路径</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@node02 sxt]# vi + /etc/profile</div><div class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67</div><div class="line">export HADOOP_PREFIX=/opt/sxt/hadoop-2.6.5</div><div class="line">export ZOOKEEPER_PREFIX=/opt/sxt/zookeeper-3.4.6</div><div class="line">export PATH=$JAVA_HOME/bin:$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin</div><div class="line">:$ZOOKEEPER_PREFIX/bin</div><div class="line">[root@node02 sxt]# . /etc/profile</div></pre></td></tr></table></figure>
<h6 id="3-配置zookeeper"><a href="#3-配置zookeeper" class="headerlink" title="3.配置zookeeper"></a>3.配置zookeeper</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[root@node02 sxt]# cd zookeeper-3.4.6/conf</div><div class="line">[root@node02 conf]# cp zoo_sample.cfg zoo.cfg</div><div class="line">[root@node02 conf]# vi zoo.cfg</div><div class="line"># zookeeper数据存放目录</div><div class="line">dataDir=/var/sxt/zookeeper</div><div class="line"># 在文件末尾追加以下内容</div><div class="line">server.1=node02:2888:3888</div><div class="line">server.2=node03:2888:3888</div><div class="line">server.3=node04:2888:3888</div><div class="line">[root@node02 conf]# mkdir /var/sxt/zookeeper</div><div class="line">[root@node02 conf]# cd /var/sxt/zookeeper/</div><div class="line">[root@node02 zookeeper]# echo 1 &gt; myid</div></pre></td></tr></table></figure>
<h5 id="4-配置node03和node04的zookeeper"><a href="#4-配置node03和node04的zookeeper" class="headerlink" title="4.配置node03和node04的zookeeper"></a>4.配置node03和node04的zookeeper</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[root@node02 sxt]# cd /opt/sxt</div><div class="line">[root@node02 sxt]# scp -r zookeeper-3.4.6 node03:`pwd`</div><div class="line">[root@node02 sxt]# scp -r zookeeper-3.4.6 node04:`pwd`</div><div class="line">[root@node02 sxt]# scp /etc/profile node03:/etc</div><div class="line">[root@node02 sxt]# scp /etc/profile node04:/etc</div><div class="line">[root@node03 ~]# . /etc/profile</div><div class="line">[root@node03 ~]# mkdir /var/sxt/zookeeper</div><div class="line">[root@node03 ~]# echo 2 &gt; /var/sxt/zookeeper/myid</div><div class="line">[root@node04 ~]# . /etc/profile</div><div class="line">[root@node04 ~]# mkdir /var/sxt/zookeeper</div><div class="line">[root@node04 ~]# echo 3 &gt; /var/sxt/zookeeper/myid</div></pre></td></tr></table></figure>
<h6 id="5-启动zookeeper集群"><a href="#5-启动zookeeper集群" class="headerlink" title="5.启动zookeeper集群"></a>5.启动zookeeper集群</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[root@node02 ~]# zkServer.sh start</div><div class="line">[root@node03 ~]# zkServer.sh start</div><div class="line">[root@node04 ~]# zkServer.sh start</div><div class="line"># 当正常启动服务的集群过半（我们这里过半是两台）时，zookeeper就可以决策出主从关系，当启动的服务不过半（我们这里是只启动一台）时，zkServer的状态是报错状态</div><div class="line">[root@node02 ~]# zkServer.sh status</div><div class="line">Mode: follower</div><div class="line">[root@node03 ~]# zkServer.sh status</div><div class="line">Mode: follower</div><div class="line">[root@node04 ~]# zkServer.sh status</div><div class="line">Mode: leader</div></pre></td></tr></table></figure>
<h6 id="6-配置hdfs，在Fully-Distributed-Mode基础上进行修改"><a href="#6-配置hdfs，在Fully-Distributed-Mode基础上进行修改" class="headerlink" title="6.配置hdfs，在Fully-Distributed Mode基础上进行修改"></a>6.配置hdfs，在Fully-Distributed Mode基础上进行修改</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node01 ~]# cd /opt/sxt/hadoop-2.6.5/etc</div><div class="line">[root@node01 etc]# cp -r hadoop hadoop-full</div><div class="line">[root@node01 etc]# cd hadoop</div></pre></td></tr></table></figure>
<h6 id="7-修改hdfs-site-xml文件"><a href="#7-修改hdfs-site-xml文件" class="headerlink" title="7.修改hdfs-site.xml文件"></a>7.修改hdfs-site.xml文件</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line">[root@node01 hadoop]# vi hdfs-site.xml</div><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;!--副本数--&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">        &lt;value&gt;2&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">&lt;!-- secondary namenode不需要了，有这个配置会报错--&gt;</div><div class="line">&lt;!--</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">        &lt;value&gt;node02:50090&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">--&gt;</div><div class="line"></div><div class="line">&lt;!--以下配置对两台NN所在的节点做了映射--&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.nameservices&lt;/name&gt;</div><div class="line">  &lt;value&gt;mycluster&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;</div><div class="line">  &lt;value&gt;nn1,nn2&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;</div><div class="line">  &lt;value&gt;node01:8020&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;</div><div class="line">  &lt;value&gt;node02:8020&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;</div><div class="line">  &lt;value&gt;node01:50070&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;</div><div class="line">  &lt;value&gt;node02:50070&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line"></div><div class="line">&lt;!--指定JNN集群位置--&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;</div><div class="line">  &lt;value&gt;qjournal://node01:8485;node02:8485;node03:8485/mycluster&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line"></div><div class="line">&lt;!--以下配置说明NN主从切换的方法--&gt;</div><div class="line">&lt;property&gt;</div><div class="line">     &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;  &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</div><div class="line">  &lt;value&gt;sshfence&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;</div><div class="line">  &lt;value&gt;/root/.ssh/id_dsa&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line"></div><div class="line">&lt;!--以下配置指定NN主从切换为自动切换--&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;</div><div class="line">   &lt;value&gt;true&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h6 id="8-修改core-site-xml"><a href="#8-修改core-site-xml" class="headerlink" title="8.修改core-site.xml"></a>8.修改core-site.xml</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">[root@node01 hadoop]# vi core-site.xml</div><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">        &lt;value&gt;hdfs://mycluster&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    </div><div class="line">    &lt;!--配置zookeeper集群--&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;</div><div class="line">        &lt;value&gt;node02:2181,node03:2181,node04:2181&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">        &lt;value&gt;/var/sxt/hadoop/ha&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h6 id="9-给node02生成公钥并分发"><a href="#9-给node02生成公钥并分发" class="headerlink" title="9.给node02生成公钥并分发"></a>9.给node02生成公钥并分发</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@node02 ~]# ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa</div><div class="line">[root@node02 ~]# cd .ssh</div><div class="line">[root@node02 .ssh]# scp ./id_dsa.pub node01:/root/node02.pub</div><div class="line">[root@node02 .ssh]# scp ./id_dsa.pub node03:/root/node02.pub</div><div class="line">[root@node02 .ssh]# scp ./id_dsa.pub node04:/root/node02.pub</div><div class="line">[root@node01 ~]# cat ~/node02.pub &gt;&gt; ~/.ssh/authorized_keys</div><div class="line">[root@node03 ~]# cat ~/node02.pub &gt;&gt; ~/.ssh/authorized_keys</div><div class="line">[root@node04 ~]# cat ~/node02.pub &gt;&gt; ~/.ssh/authorized_keys</div></pre></td></tr></table></figure>
<p>还有更简单的方法，在node01中，vi authorized_keys，复制文件中的内容，在末尾粘贴3份，只修改最后的节点名称为node02、node03、node04<br><img src="/media/15047700236821.jpg" alt=""><br>然后把.ssh文件夹分发给node02、node03、node04<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node01 .ssh]# scp ./* node02:`pwd`</div><div class="line">[root@node01 .ssh]# scp ./* node03:`pwd`</div><div class="line">[root@node01 .ssh]# scp ./* node04:`pwd`</div></pre></td></tr></table></figure></p>
<h6 id="10-将hadoop文件夹分发"><a href="#10-将hadoop文件夹分发" class="headerlink" title="10.将hadoop文件夹分发"></a>10.将hadoop文件夹分发</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node01 ~]# cd /opt/sxt</div><div class="line">[root@node01 sxt]# scp -r hadoop-2.6.5/ node02:`pwd`</div><div class="line">[root@node01 sxt]# scp -r hadoop-2.6.5/ node03:`pwd`</div><div class="line">[root@node01 sxt]# scp -r hadoop-2.6.5/ node04:`pwd`</div></pre></td></tr></table></figure>
<h6 id="11-启动JNN集群"><a href="#11-启动JNN集群" class="headerlink" title="11.启动JNN集群"></a>11.启动JNN集群</h6><p>[root@node01 ~]# hadoop-daemon.sh start journalnode<br>[root@node02 ~]# hadoop-daemon.sh start journalnode<br>[root@node03 ~]# hadoop-daemon.sh start journalnode</p>
<h6 id="12-在node01中执行格式化"><a href="#12-在node01中执行格式化" class="headerlink" title="12.在node01中执行格式化"></a>12.在node01中执行格式化</h6><p>[root@node01 ~]# hdfs namenode –format<br>[root@node01 ~]# hadoop-daemon.sh start namenode #手动启动namenode，只启动本机</p>
<h6 id="13-在node02中执行如下命令"><a href="#13-在node02中执行如下命令" class="headerlink" title="13.在node02中执行如下命令"></a>13.在node02中执行如下命令</h6><p><code>[root@node02 ~]# hdfs namenode -bootstrapStandby</code></p>
<h6 id="14-格式化zkfc"><a href="#14-格式化zkfc" class="headerlink" title="14.格式化zkfc"></a>14.格式化zkfc</h6><p><code>[root@node01 ~]# hdfs zkfc –formatZK</code><br><code>[root@node01 ~]# hadoop-daemon.sh start zkfc #手动启动zkfc</code></p>
<h6 id="15-启动hdfs集群"><a href="#15-启动hdfs集群" class="headerlink" title="15.启动hdfs集群"></a>15.启动hdfs集群</h6><p><code>[root@node01 ~]# start-dfs.sh</code><br>验证：<br><img src="/media/15047703288204.jpg" alt=""><br><img src="/media/15047703474873.jpg" alt=""><br>杀死node02的namenode进程：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@node02 ~]# jps</div><div class="line">2284 Jps</div><div class="line">2090 JournalNode</div><div class="line">1951 NameNode</div><div class="line">1317 QuorumPeerMain</div><div class="line">2197 DFSZKFailoverController</div><div class="line">2012 DataNode</div><div class="line">[root@node02 ~]# kill -9 1951</div></pre></td></tr></table></figure></p>
<p><img src="/media/15047703774393.jpg" alt=""><br><img src="/media/15047703934909.jpg" alt=""><br>SNN变成了ANN！<br>恢复node02的NameNode进程：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@node02 ~]# hadoop-daemon.sh start namenode</div><div class="line">[root@node02 ~]# jps</div><div class="line">2407 Jps</div><div class="line">2090 JournalNode</div><div class="line">2330 NameNode</div><div class="line">1317 QuorumPeerMain</div><div class="line">2197 DFSZKFailoverController</div><div class="line">2012 DataNode</div></pre></td></tr></table></figure></p>
<p>node02并不会切换回ANN，而是成为了SNN<br><img src="/media/15047704421563.jpg" alt=""><br>关闭node01的namenode进程后，node02也会变为ANN<br>命令行验证：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node01 ~]# hdfs dfs -mkdir -p /user/root</div><div class="line">[root@node01 ~]# hdfs dfs -D dfs.blocksize=1048576 -put nginx</div></pre></td></tr></table></figure></p>
<p><img src="/media/15047704806769.jpg" alt=""></p>
<h3 id="Hadoop-API"><a href="#Hadoop-API" class="headerlink" title="Hadoop API"></a>Hadoop API</h3><p>参见我的另外两篇博客：</p>
<ol>
<li><a href="http://chant00.com/2016/07/05/Hadoop-eclipseConnectHadoop/">HADOOP–mac下eclipse连接hadoop集群开发API</a></li>
<li><a href="http://chant00.com/2016/07/05/Hadoop-IDEAConnectHadoop/">HADOOP–mac下IDEA连接hadoop集群开发API</a></li>
</ol>
<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><h4 id="语义"><a href="#语义" class="headerlink" title="语义"></a>语义</h4><p>MapTask &amp; ReduceTask<br>相同的Key为一组，调用一次Reduce</p>
<h4 id="MapReduce原理"><a href="#MapReduce原理" class="headerlink" title="MapReduce原理"></a>MapReduce原理</h4><p><img src="/media/15047725214328.jpg" alt=""></p>
<p>Map的数量=文件大小/split大小，split和block都有偏移量<br><img src="/media/15047726233991.jpg" alt=""><br>一切都是从最上方的user program开始的，user program链接了MapReduce库，实现了最基本的Map函数和Reduce函数。图中执行的顺序都用数字标记了。</p>
<ol>
<li>MapReduce库先把user program的输入文件划分为M份（M为用户定义），每一份通常有16MB到64MB，如图左方所示分成了split0-4；然后使用fork将用户进程拷贝到集群内其它机器上。 </li>
<li>user program的副本中有一个称为master，其余称为worker，master是负责调度的，为空闲worker分配作业（Map作业或者Reduce作业），worker的数量也是可以由用户指定的。 </li>
<li>被分配了Map作业的worker，开始读取对应分片的输入数据，Map作业数量是由M决定的，和split一一对应；Map作业从输入数据中抽取出键值对，每一个键值对都作为参数传递给map函数，map函数产生的中间键值对被缓存在内存中。 </li>
<li>缓存的中间键值对会被定期写入本地磁盘，而且被分为R个区，R的大小是由用户定义的，将来每个区会对应一个Reduce作业；这些中间键值对的位置会被通报给master，master负责将信息转发给Reduce worker。 </li>
<li>master通知分配了Reduce作业的worker它负责的分区在什么位置（肯定不止一个地方，每个Map作业产生的中间键值对都可能映射到所有R个不同分区），当Reduce worker把所有它负责的中间键值对都读过来后，先对它们进行排序，使得相同键的键值对聚集在一起。因为不同的键可能会映射到同一个分区也就是同一个Reduce作业（谁让分区少呢），所以排序是必须的。 reduce worker遍历排序后的中间键值对，对于每个唯一的键，都将键与关联的值传递给reduce函数，reduce函数产生的输出会添加到这个分区的输出文件中。 </li>
<li>当所有的Map和Reduce作业都完成了，master唤醒正版的user program，MapReduce函数调用返回user program的代码。 </li>
<li>所有执行完毕后，MapReduce输出放在了R个分区的输出文件中（分别对应一个Reduce作业）。用户通常并不需要合并这R个文件，而是将其作为输入交给另一个MapReduce程序处理。整个过程中，输入数据是来自底层分布式文件系统（HDFS）的，中间数据是放在本地文件系统的，最终输出数据是写入底层分布式文件系统（HDFS）的。而且我们要注意Map/Reduce作业和map/reduce函数的区别：Map作业处理一个输入数据的分片，可能需要调用多次map函数来处理每个输入键值对；Reduce作业处理一个分区的中间键值对，期间要对每个不同的键调用一次reduce函数，Reduce作业最终也对应一个输出文件。</li>
</ol>
<p>要点：<br>Map：读懂数据、映射为KV模型、并行分布式、计算向数据移动<br>Reduce：数据全量/分量加工、相同的Key汇聚到一个Reduce中、相同的Key调用一次reduce方法、Reduce中可以包含不同的key、排序实现key的汇聚<br>K、V：使用自定义数据类型，作为参数传递，节省开发成本，提高程序自由度<br>Writable序列化：分布式程序数据交互<br>Comparable比较器：实现具体排序（字典序，数值序等）</p>
<h4 id="MapReduce任务中Shuffle和排序的过程"><a href="#MapReduce任务中Shuffle和排序的过程" class="headerlink" title="MapReduce任务中Shuffle和排序的过程"></a>MapReduce任务中Shuffle和排序的过程</h4><p><img src="/media/15047726886506.jpg" alt=""><br><img src="/media/15047727091464.jpg" alt=""><br>流程分析：</p>
<p>Map端： </p>
<ol>
<li>每个输入分片会让一个map任务来处理，默认情况下，以HDFS的一个块的大小（默认为64M）为一个分片，当然我们也可以设置块的大小。map输出的结果会暂且放在一个环形内存缓冲区中（该缓冲区的大小默认为100M，由io.sort.mb属性控制），当该缓冲区快要溢出时（默认为缓冲区大小的80%，由io.sort.spill.percent属性控制），会在本地文件系统中创建一个溢出文件，将该缓冲区中的数据写入这个文件。</li>
<li>在写入磁盘之前，线程首先根据reduce任务的数目将数据划分为相同数目的分区，也就是一个reduce任务对应一个分区的数据。分区就是给数据打一个标签，让它被某个固定的reduce执行，这样做是为了避免有些reduce任务分配到大量数据，而有些reduce任务却分到很少数据，甚至没有分到数据的尴尬局面。其实分区就是对数据进行hash的过程。然后对每个分区中的数据进行排序，如果此时设置了Combiner，将排序后的结果进行combine操作，这样做的目的是让尽可能少的数据写入到磁盘。</li>
<li>当map任务输出最后一个记录时，可能会有很多的溢出文件，这时需要将这些文件合并。合并的过程中会不断地进行排序和combine操作，目的有两个：1)尽量减少每次写入磁盘的数据量；2)尽量减少下一复制阶段网络传输的数据量。最后合并成了一个已分区且已排序的文件。为了减少网络传输的数据量，这里可以将数据压缩，只要将mapred.compress.map.out设置为true就可以了。</li>
<li>将分区中的数据拷贝给相对应的reduce任务。分区中的数据怎么知道它对应的reduce是哪个呢？其实map任务一直和其父进程TaskTracker保持联系，而TaskTracker又一直和JobTracker保持心跳。所以JobTracker中保存了整个集群中的宏观信息。只要reduce任务向JobTracker获取对应的map输出位置就ok了哦。<br>到这里，map端就分析完了。那到底什么是Shuffle呢？Shuffle的中文意思是“洗牌”，一个map产生的数据，结果通过hash过程分区却分配给了不同的reduce任务，就是一个对数据洗牌的过程。</li>
</ol>
<p>Reduce端： </p>
<ol>
<li>Reduce会接收到不同map任务传来的数据，并且每个map传来的数据都是有序的。如果reduce端接受的数据量相当小，则直接存储在内存中（缓冲区大小由mapred.job.shuffle.input.buffer.percent属性控制，表示用作此用途的堆空间的百分比），如果数据量超过了该缓冲区大小的一定比例（由mapred.job.shuffle.merge.percent决定），则对数据合并后溢写到磁盘中。</li>
<li>随着溢写文件的增多，后台线程会将它们合并成一个更大的有序的文件，这样做是为了给后面的合并节省时间。其实不管在map端还是reduce端，MapReduce都是反复地执行排序，合并操作，现在终于明白了有些人为什么会说：排序是hadoop的灵魂。</li>
<li><p>合并的过程中会产生许多的中间文件（写入磁盘了），但MapReduce会让写入磁盘的数据尽可能地少，并且最后一次合并的结果并没有写入磁盘，而是直接输入到reduce函数。</p>
<h4 id="MapReduce运行框架"><a href="#MapReduce运行框架" class="headerlink" title="MapReduce运行框架"></a>MapReduce运行框架</h4><p><img src="/media/15047755445312.jpg" alt=""><br>计算框架Mapper：<br><img src="/media/15047755620372.jpg" alt=""><br>计算框架Reducer：<br><img src="/media/15047755831091.jpg" alt=""><br><img src="/media/15047755995512.jpg" alt=""></p>
</li>
<li><p>在客户端启动一个作业。</p>
</li>
<li>向JobTracker请求一个Job ID。</li>
<li>将运行作业所需要的资源文件复制到HDFS上，包括MapReduce程序打包的JAR文件、配置文件和客户端计算所得的输入划分信息。这些文件都存放在JobTracker专门为该作业创建的文件夹中。文件夹名为该作业的Job ID。JAR文件默认会有10个副本（mapred.submit.replication属性控制）；输入划分信息告诉了JobTracker应该为这个作业启动多少个map任务等信息。</li>
<li>JobTracker接收到作业后，将其放在一个作业队列里，等待作业调度器对其进行调度（很像微机中的进程调度），当作业调度器根据自己的调度算法调度到该作业时，会根据输入划分信息为每个划分创建一个map任务，并将map任务分配给TaskTracker执行。对于map和reduce任务，TaskTracker根据主机核的数量和内存的大小有固定数量的map槽和reduce槽。这里需要强调的是：map任务不是随随便便地分配给某个TaskTracker的，这里有个概念叫：数据本地化（Data-Local）。意思是：将map任务分配给含有该map处理的数据块的TaskTracker上，同时将程序JAR包复制到该TaskTracker上来运行，这叫“计算移动，数据不移动”。而分配reduce任务时并不考虑数据本地化。</li>
<li>TaskTracker每隔一段时间会给JobTracker发送一个心跳，告诉JobTracker它依然在运行，同时心跳中还携带着很多的信息，比如当前map任务完成的进度等信息。当JobTracker收到作业的最后一个任务完成信息时，便把该作业设置成“成功”。当JobClient查询状态时，它将得知任务已完成，便显示一条消息给用户。</li>
</ol>
<p>以上是在客户端、JobTracker、TaskTracker的层次来分析MapReduce的工作原理的。</p>
<p>MR 1.x中：<br>JobTracker<br>核心、主、单点、调度所有的作业、监控整个集群的资源负载<br>TaskTracker<br>从，自身节点资源管理、和JobTracker心跳，汇报资源，获取Task<br>Client<br>作业为单位、规划作业计算分布、提交作业资源到HDFS、最终提交作业到JobTracker<br>弊端：<br>JobTracker负载过重，单点故障；<br>资源管理与计算调度强耦合，其他计算框架需要重复实现资源管理；<br>不同框架对资源不能全局管理。</p>
<h4 id="Yarn资源调度"><a href="#Yarn资源调度" class="headerlink" title="Yarn资源调度"></a>Yarn资源调度</h4><p><img src="/media/15047845502828.jpg" alt=""><br><img src="/media/15047845869358.jpg" alt=""><br>MR 2.x：On YARN<br>YARN：解耦资源与计算<br>ResourceManager：主，核心，集群节点资源管理<br>NodeManager：与RM汇报资源，管理Container生命周期，计算框架中的角色都以Container表示<br>Container：其中信息包括节点NM，CPU，MEM，I/O大小，启动命令等，默认NodeManager启动线程监控Container大小，超出申请资源额度，则kill，支持Linux内核的Cgroup<br>MR ：MR-ApplicationMaster-Container，作业为单位，避免单点故障，负载到不同的节点，创建Task需要和RM申请资源（Container），<br>Task：也是运行在Container中<br>Client：RM-Client：请求资源创建AM，AM-Client：与AM交互</p>
<h3 id="搭建基于yarn的mapreduce框架"><a href="#搭建基于yarn的mapreduce框架" class="headerlink" title="搭建基于yarn的mapreduce框架"></a>搭建基于yarn的mapreduce框架</h3><h4 id="角色划分-1"><a href="#角色划分-1" class="headerlink" title="角色划分"></a>角色划分</h4><p><img src="/media/15047846573345.jpg" alt=""><br>在HDFS 2.x HA的基础上进行配置</p>
<h6 id="1-编辑mapred-site-xml"><a href="#1-编辑mapred-site-xml" class="headerlink" title="1.编辑mapred-site.xml"></a>1.编辑mapred-site.xml</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[root@node01 ~]# cd /opt/sxt/hadoop-2.6.5/etc/hadoop/</div><div class="line">[root@node01 hadoop]# cp mapred-site.xml.template mapred-site.xml</div><div class="line">[root@node01 hadoop]# vi mapred-site.xml</div><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">        &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h6 id="2-编辑yarn-site-xml"><a href="#2-编辑yarn-site-xml" class="headerlink" title="2.编辑yarn-site.xml"></a>2.编辑yarn-site.xml</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">[root@node01 hadoop]# vi yarn-site.xml</div><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;</div><div class="line">        &lt;value&gt;true&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;</div><div class="line">        &lt;value&gt;cluster1&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;</div><div class="line">        &lt;value&gt;rm1,rm2&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;</div><div class="line">        &lt;value&gt;node03&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;</div><div class="line">        &lt;value&gt;node04&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;</div><div class="line">        &lt;value&gt;node02:2181,node03:2181,node04:2181&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h6 id="3-分发配置"><a href="#3-分发配置" class="headerlink" title="3.分发配置"></a>3.分发配置</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node01 hadoop]# scp mapred-site.xml yarn-site.xml node02:`pwd`   </div><div class="line">[root@node01 hadoop]# scp mapred-site.xml node02:`pwd`</div><div class="line">[root@node01 hadoop]# scp mapred-site.xml yarn-site.xml node03:`pwd`  </div><div class="line">[root@node01 hadoop]# scp mapred-site.xml node03:`pwd`</div><div class="line">[root@node01 hadoop]# scp mapred-site.xml yarn-site.xml node04:`pwd`</div><div class="line">[root@node01 hadoop]# scp mapred-site.xml node04:`pwd`</div></pre></td></tr></table></figure>
<h6 id="4-启动yarn"><a href="#4-启动yarn" class="headerlink" title="4.启动yarn"></a>4.启动yarn</h6><p><code>[root@node01 hadoop]# start-yarn.sh</code></p>
<h6 id="5-手工启动ResourceManager"><a href="#5-手工启动ResourceManager" class="headerlink" title="5.手工启动ResourceManager"></a>5.手工启动ResourceManager</h6><p><code>[root@node03 ~]# yarn-daemon.sh start resourcemanager</code><br><img src="/media/15047848080086.jpg" alt=""><br>配置成功！</p>
<p>访问node04:8088，出现提示后跳转到node03（active）<br><img src="/media/15047848212089.jpg" alt=""></p>
<p>Kill node03的RM进程，node04的RM变为active，再次启动node03的RM进程，主从关系不变，即node04是active，node03是standby。</p>
<h4 id="运行框架自带的例子程序"><a href="#运行框架自带的例子程序" class="headerlink" title="运行框架自带的例子程序"></a>运行框架自带的例子程序</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">[root@node01 ~]# cd pwd/opt/sxt/hadoop-2.6.5/share/hadoop/mapreduce</div><div class="line">[root@node01 mapreduce]# ll -h</div><div class="line">total 4.8M</div><div class="line">-rw-r--r-- 1 root root 517K Jul  8 12:00 hadoop-mapreduce-client-app-2.6.5.jar</div><div class="line">-rw-r--r-- 1 root root 673K Jul  8 12:00 hadoop-mapreduce-client-common-2.6.5.jar</div><div class="line">-rw-r--r-- 1 root root 1.5M Jul  8 12:00 hadoop-mapreduce-client-core-2.6.5.jar</div><div class="line">-rw-r--r-- 1 root root 254K Jul  8 12:00 hadoop-mapreduce-client-hs-2.6.5.jar</div><div class="line">-rw-r--r-- 1 root root  27K Jul  8 12:00 hadoop-mapreduce-client-hs-plugins-2.6.5.Jar</div><div class="line">-rw-r--r-- 1 root root  60K Jul  8 12:00 hadoop-mapreduce-client-jobclient-2.6.5.jar</div><div class="line">-rw-r--r-- 1 root root 1.5M Jul  8 12:00 hadoop-mapreduce-client-jobclient-2.6.5-tests.jar</div><div class="line">-rw-r--r-- 1 root root  67K Jul  8 12:00 hadoop-mapreduce-client-shuffle-2.6.5.jar</div><div class="line">-rw-r--r-- 1 root root 287K Jul  8 12:00 hadoop-mapreduce-examples-2.6.5.jar</div><div class="line">[root@node01 mapreduce]# vi /tmp/hello.txt</div><div class="line">Java C C++ Hadoop</div><div class="line">MySQL Oracle Java Java</div><div class="line">C C C MySQL MySQL </div><div class="line">Spring SpringMVC Java</div><div class="line">C++</div><div class="line">[root@node01 mapreduce]# hdfs dfs -mkdir /user/root/wordcount/input</div><div class="line">[root@node01 mapreduce]# hdfs dfs -put /tmp/hello.txt /user/root/wordcount/input/wordcount.txt</div><div class="line">[root@node01 mapreduce]# hadoop jar hadoop-mapreduce-examples-2.6.5.jar wordcount </div><div class="line">/user/root/wordcount/input /user/root/wordcount/output</div><div class="line">[root@node01 mapreduce]# hdfs dfs -ls /user/root/wordcount/output</div><div class="line">Found 2 items</div><div class="line">-rw-r--r--   2 root supergroup          0 2017-07-10 16:18 /user/root/wordcount/ou</div><div class="line">tput/_SUCCESS</div><div class="line">-rw-r--r--   2 root supergroup         64 2017-07-10 16:18 /user/root/wordcount/ou</div><div class="line">tput/part-r-00000</div><div class="line">[root@node01 mapreduce]# hdfs dfs -cat /user/root/wordcount/output/part-r-00000</div><div class="line">C	4</div><div class="line">C++	2</div><div class="line">Hadoop	1</div><div class="line">Java	4</div><div class="line">MySQL	3</div><div class="line">Oracle	1</div><div class="line">Spring	1</div><div class="line">SpringMVC	1</div></pre></td></tr></table></figure>
<h3 id="Hadoop案例：WordCount"><a href="#Hadoop案例：WordCount" class="headerlink" title="Hadoop案例：WordCount"></a>Hadoop案例：WordCount</h3><h4 id="Job类"><a href="#Job类" class="headerlink" title="Job类"></a>Job类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyJob</span> </span>&#123;</div><div class="line">     </div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">         </div><div class="line">         Configuration conf = <span class="keyword">new</span> Configuration(<span class="keyword">true</span>);</div><div class="line">         </div><div class="line">         Job job = Job.getInstance(conf);</div><div class="line">         </div><div class="line">          <span class="comment">// Create a new Job</span></div><div class="line">          <span class="comment">//Job job = Job.getInstance();</span></div><div class="line">          job.setJarByClass(MyJob.class);</div><div class="line">         </div><div class="line">          <span class="comment">// Specify various job-specific parameters    </span></div><div class="line">          job.setJobName(<span class="string">"myjob"</span>);</div><div class="line">         </div><div class="line">          <span class="comment">//job.setInputPath(new Path("in"));</span></div><div class="line">          <span class="comment">//job.setOutputPath(new Path("out"));</span></div><div class="line">         </div><div class="line">          Path input = <span class="keyword">new</span> Path(<span class="string">"/user/root/wordcount/input"</span>);</div><div class="line">          FileInputFormat.addInputPath(job, input);</div><div class="line">          Path output = <span class="keyword">new</span> Path(<span class="string">"/user/root/wordcount/output"</span>);</div><div class="line">          <span class="keyword">if</span> ( output.getFileSystem(conf).exists(output))&#123;</div><div class="line">           output.getFileSystem(conf).delete(output, <span class="keyword">true</span>);</div><div class="line">          &#125;</div><div class="line">          FileOutputFormat.setOutputPath(job, output);</div><div class="line">        </div><div class="line">          job.setMapperClass(MyMapper.class);</div><div class="line">          job.setMapOutputKeyClass(Text.class);</div><div class="line">          job.setMapOutputValueClass(IntWritable.class);</div><div class="line">          job.setReducerClass(MyReducer.class);</div><div class="line">          <span class="comment">// Submit the job, then poll for progress until the job is complete</span></div><div class="line">          job.waitForCompletion(<span class="keyword">true</span>);</div><div class="line">     &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="Mapper类"><a href="#Mapper类" class="headerlink" title="Mapper类"></a>Mapper类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line">     </div><div class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable ONE = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</div><div class="line">        <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</div><div class="line">       </div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span></span></div><div class="line">                 <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">          StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</div><div class="line">          <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</div><div class="line">            word.set(itr.nextToken());</div><div class="line">            context.write(word, ONE);</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="Reducer类"><a href="#Reducer类" class="headerlink" title="Reducer类"></a>Reducer类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</div><div class="line">     </div><div class="line">        <span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</div><div class="line">       </div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span></span></div><div class="line">                 <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">          <span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">          <span class="keyword">for</span> (IntWritable val : values) &#123;</div><div class="line">            sum += val.get();</div><div class="line">          &#125;</div><div class="line">          result.set(sum);</div><div class="line">          context.write(key, result);</div><div class="line">        &#125;</div><div class="line">     </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="在集群中运行程序步骤"><a href="#在集群中运行程序步骤" class="headerlink" title="在集群中运行程序步骤"></a>在集群中运行程序步骤</h4><ol>
<li>导出Jar包</li>
<li>把jar包上传到服务器</li>
<li>执行jar包</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@node01 ~]# hadoop jar /var/sxt/hadoop/jar/WordCount.jar com.sxt.hadoop.mapre</div><div class="line">duce.wordcount.MyJob</div><div class="line">[root@node01 ~]# hdfs dfs -ls /user/root/wordcount/output</div><div class="line">Found 2 items</div><div class="line">-rw-r--r--   2 root supergroup          0 2017-07-10 20:38 /user/root/wordcount/output/_SUCCESS</div><div class="line">-rw-r--r--   2 root supergroup         64 2017-07-10 20:38 /user/root/wordcount/output/part-r-00000</div><div class="line">[root@node01 ~]# hdfs dfs -cat /user/root/wordcount/output/part-r-00000</div><div class="line">C	4</div><div class="line">C++	2</div><div class="line">Hadoop	1</div><div class="line">Java	4</div><div class="line">MySQL	3</div><div class="line">Oracle	1</div><div class="line">Spring	1</div><div class="line">SpringMVC	1</div></pre></td></tr></table></figure>
<h3 id="MapReduce源码分析"><a href="#MapReduce源码分析" class="headerlink" title="MapReduce源码分析"></a>MapReduce源码分析</h3><h4 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h4><p>waitForCompletion()调用submit()<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">waitForCompletion</span><span class="params">(<span class="keyword">boolean</span> verbose)</span> </span></div><div class="line"><span class="keyword">throws</span> IOException, InterruptedException,</div><div class="line">                             ClassNotFoundException &#123;</div><div class="line">    <span class="keyword">if</span> (state == JobState.DEFINE) &#123;</div><div class="line">       <span class="comment">//重点是提交的过程</span></div><div class="line">submit();</div><div class="line">    &#125;</div><div class="line"><span class="keyword">if</span> (verbose) &#123;</div><div class="line">  <span class="comment">//监控并打印执行过程</span></div><div class="line">      monitorAndPrintJob();</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      ……</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> isSuccessful();</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>submit()调用submitJobInternal()方法把作业提交到集群<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">submit</span><span class="params">()</span></span></div><div class="line">         <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</div><div class="line">ensureState(JobState.DEFINE);</div><div class="line"><span class="comment">//判断使用的是hadoop 1.x还是2.x的jar包</span></div><div class="line">setUseNewAPI();</div><div class="line"><span class="comment">//连接集群</span></div><div class="line">    connect();</div><div class="line">    <span class="keyword">final</span> JobSubmitter submitter =</div><div class="line">        getJobSubmitter(cluster.getFileSystem(), cluster.getClient());</div><div class="line">    status = ugi.doAs(<span class="keyword">new</span> PrivilegedExceptionAction&lt;JobStatus&gt;() &#123;</div><div class="line">             <span class="function"><span class="keyword">public</span> JobStatus <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException,</span></div><div class="line">                                   ClassNotFoundException &#123;</div><div class="line">              <span class="comment">//把作业提交到集群</span></div><div class="line">             <span class="keyword">return</span> submitter.submitJobInternal(Job.<span class="keyword">this</span>, cluster);</div><div class="line">             &#125;</div><div class="line">        &#125;);</div><div class="line">    ……</div><div class="line">   &#125;</div></pre></td></tr></table></figure></p>
<p>submitJobInternal()方法详解<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div></pre></td><td class="code"><pre><div class="line"><span class="function">JobStatus <span class="title">submitJobInternal</span><span class="params">(Job job, Cluster cluster)</span></span></div><div class="line">  <span class="keyword">throws</span> ClassNotFoundException, InterruptedException, IOException &#123;</div><div class="line"><span class="comment">//validate the jobs output specs</span></div><div class="line"><span class="comment">//Checking the input and output specifications of the job. 检查输入输出路径</span></div><div class="line">    checkSpecs(job);</div><div class="line">    Configuration conf = job.getConfiguration();</div><div class="line">    addMRFrameworkToDistributedCache(conf);</div><div class="line">    Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);</div><div class="line">    <span class="comment">//configure the command line options correctly on the submitting dfs</span></div><div class="line">    InetAddress ip = InetAddress.getLocalHost();</div><div class="line"><span class="keyword">if</span> (ip != <span class="keyword">null</span>) &#123;</div><div class="line">  <span class="comment">//封装提交的信息</span></div><div class="line">      submitHostAddress = ip.getHostAddress();</div><div class="line">      submitHostName = ip.getHostName();</div><div class="line">      conf.set(MRJobConfig.JOB_SUBMITHOST,submitHostName);</div><div class="line">      conf.set(MRJobConfig.JOB_SUBMITHOSTADDR,</div><div class="line">submitHostAddress);</div><div class="line">    &#125;</div><div class="line">    JobID jobId = submitClient.getNewJobID();</div><div class="line">job.setJobID(jobId);</div><div class="line"><span class="comment">//获得提交的目录</span></div><div class="line">    Path submitJobDir = <span class="keyword">new</span> Path(jobStagingArea, jobId.toString());</div><div class="line">    JobStatus status = <span class="keyword">null</span>;</div><div class="line">    ……</div><div class="line"></div><div class="line">       <span class="comment">//copy配置文件</span></div><div class="line">      copyAndConfigureFiles(job, submitJobDir);</div><div class="line">      Path submitJobFile = JobSubmissionFiles.getJobConfPath(submitJobDir);</div><div class="line">     </div><div class="line">      <span class="comment">// Create the splits for the job创建切片</span></div><div class="line">      LOG.debug(<span class="string">"Creating splits at "</span> + jtFs.makeQualified(submitJobDir));</div><div class="line">       <span class="comment">//创建切片的方法</span></div><div class="line">      <span class="keyword">int</span> maps = writeSplits(job, submitJobDir);</div><div class="line"></div><div class="line">writeSplits()调用writeNewSplits()</div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">writeSplits</span><span class="params">(</span></span></div><div class="line">org.apache.hadoop.mapreduce.JobContext job,</div><div class="line">       Path jobSubmitDir) </div><div class="line"><span class="keyword">throws</span> IOException,</div><div class="line">      InterruptedException, ClassNotFoundException &#123;</div><div class="line">    JobConf jConf = (JobConf)job.getConfiguration();</div><div class="line"><span class="keyword">int</span> maps;</div><div class="line"><span class="comment">//根据前面的信息选择使用1.x或者2.x的配置</span></div><div class="line">    <span class="keyword">if</span> (jConf.getUseNewMapper()) &#123;</div><div class="line">      maps = writeNewSplits(job, jobSubmitDir);</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      maps = writeOldSplits(jConf, jobSubmitDir);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> maps;</div><div class="line">&#125;</div><div class="line"></div><div class="line">writeNewSplits()</div><div class="line"><span class="keyword">private</span> &lt;T extends InputSplit&gt;</div><div class="line">  <span class="function"><span class="keyword">int</span> <span class="title">writeNewSplits</span><span class="params">(JobContext job, Path jobSubmitDir)</span> <span class="keyword">throws</span> IOException,</span></div><div class="line">      InterruptedException, ClassNotFoundException &#123;</div><div class="line">Configuration conf = job.getConfiguration();</div><div class="line"><span class="comment">//通过反射得到InputFormatClass</span></div><div class="line">    InputFormat&lt;?, ?&gt; input =</div><div class="line">      ReflectionUtils.newInstance(</div><div class="line">job.getInputFormatClass(), conf);</div><div class="line"></div><div class="line">getInputFormatClass()</div><div class="line"> <span class="keyword">public</span> Class&lt;? extends InputFormat&lt;?,?&gt;&gt; getInputFormatClass()</div><div class="line">     <span class="keyword">throws</span> ClassNotFoundException &#123;</div><div class="line"><span class="keyword">return</span> (Class&lt;? extends InputFormat&lt;?,?&gt;&gt;)</div><div class="line"><span class="comment">//如果用户设置过InputFormat,</span></div><div class="line"><span class="comment">//job.setInputFormatClass(cls);</span></div><div class="line"><span class="comment">//就使用用户设置的</span></div><div class="line"><span class="comment">//否则使用默认的Text</span></div><div class="line">      conf.getClass(INPUT_FORMAT_CLASS_ATTR, TextInputFormat.class);</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">List&lt;InputSplit&gt; splits = input.getSplits(job);</div><div class="line"></div><div class="line">getSplits()</div><div class="line"> <span class="function"><span class="keyword">public</span> List&lt;InputSplit&gt; <span class="title">getSplits</span><span class="params">(JobContext job)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">Stopwatch sw = <span class="keyword">new</span> Stopwatch().start();</div><div class="line"><span class="comment">//在用户没有干预的情况下，值为1</span></div><div class="line"><span class="keyword">long</span> minSize = </div><div class="line">Math.max(</div><div class="line">getFormatMinSplitSize(),getMinSplitSize(job)</div><div class="line">);</div><div class="line"><span class="comment">/*</span></div><div class="line">protected long getFormatMinSplitSize() &#123;</div><div class="line">            return 1;</div><div class="line">       &#125;</div><div class="line">        public static long getMinSplitSize(</div><div class="line">JobContext job) &#123;</div><div class="line">如果用户设置了，用用户设置的值，否则使用1</div><div class="line">//FileInputFormat.setMinInputSplitSize(job, size);</div><div class="line">return job.getConfiguration()</div><div class="line">.getLong(SPLIT_MINSIZE, 1L);</div><div class="line">    &#125;</div><div class="line">*/</div><div class="line"><span class="keyword">long</span> maxSize = getMaxSplitSize(job); </div><div class="line"><span class="comment">/* </span></div><div class="line">如果用户设置了，去用户的值，否则去一个无限大的值</div><div class="line">public static long getMaxSplitSize(</div><div class="line">JobContext context) &#123;</div><div class="line">           return context.getConfiguration()</div><div class="line">.getLong(</div><div class="line">SPLIT_MAXSIZE,Long.MAX_VALUE);</div><div class="line">     &#125;</div><div class="line">*/  </div><div class="line">    <span class="comment">// generate splits</span></div><div class="line">    List&lt;InputSplit&gt; splits = <span class="keyword">new</span> ArrayList&lt;InputSplit&gt;();</div><div class="line">List&lt;FileStatus&gt; files = listStatus(job);</div><div class="line"><span class="comment">//迭代用户给的目录下的所有文件，得到每个文件的</span></div><div class="line"><span class="comment">//BlockLocations</span></div><div class="line">    <span class="keyword">for</span> (FileStatus file: files) &#123;</div><div class="line">      Path path = file.getPath();</div><div class="line">      <span class="keyword">long</span> length = file.getLen();</div><div class="line">      <span class="keyword">if</span> (length != <span class="number">0</span>) &#123;</div><div class="line">        BlockLocation[] blkLocations;</div><div class="line">        <span class="keyword">if</span> (file <span class="keyword">instanceof</span> LocatedFileStatus) &#123;</div><div class="line">          blkLocations = ((LocatedFileStatus) file).getBlockLocations();</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          FileSystem fs = path.getFileSystem(job.getConfiguration());</div><div class="line">          blkLocations = fs.getFileBlockLocations(file, <span class="number">0</span>, length);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (isSplitable(job, path)) &#123;</div><div class="line">          <span class="keyword">long</span> blockSize = file.getBlockSize();</div><div class="line">          <span class="keyword">long</span> splitSize = computeSplitSize(blockSize, minSize, maxSize);</div><div class="line">       <span class="comment">/*</span></div><div class="line">     在用户没有干预的情况下</div><div class="line">     取maxSize和blockSize的最小值，默认情况下为blockSize</div><div class="line">     取blockSize和minSize的最大值，最后结果为blockSize</div><div class="line">       protected long computeSplitSize(</div><div class="line">long blockSize, long minSize,long maxSize) &#123;</div><div class="line">return </div><div class="line">Math.max(minSize, Math.min(maxSize, blockSize));</div><div class="line">  &#125;</div><div class="line">*/</div><div class="line">          <span class="keyword">long</span> bytesRemaining = length;</div><div class="line">          <span class="keyword">while</span> (((<span class="keyword">double</span>) bytesRemaining)/splitSize &gt; SPLIT_SLOP) &#123;</div><div class="line">             <span class="comment">//计算切片属于哪个block</span></div><div class="line">            <span class="keyword">int</span> blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);</div><div class="line">  <span class="comment">/*</span></div><div class="line">protected int getBlockIndex(</div><div class="line">BlockLocation[] blkLocations,long offset) &#123;</div><div class="line">    判断offset在block块的偏移量的哪个范围</div><div class="line">    for (int i = 0 ; i &lt; blkLocations.length; i++) &#123;</div><div class="line">      // is the offset inside this block?</div><div class="line">      if ((blkLocations[i].getOffset() &lt;= offset) &amp;&amp;</div><div class="line">          (offset &lt; blkLocations[i].getOffset() + blkLocations[i].getLength()))&#123;</div><div class="line">        return i;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">BlockLocation last =</div><div class="line">blkLocations[blkLocations.length -1];</div><div class="line">    long fileLength = last.getOffset() + last.getLength() -1;</div><div class="line">throw new IllegalArgumentException(</div><div class="line">"Offset " + offset +" is outside of file (0.." +</div><div class="line">                                   fileLength + ")");</div><div class="line">  &#125;</div><div class="line">*/</div><div class="line">            splits.add(makeSplit(path, </div><div class="line">length-bytesRemaining, splitSize,</div><div class="line">                      blkLocations[blkIndex].getHosts(),</div><div class="line">              blkLocations[blkIndex].getCachedHosts()));</div><div class="line">            bytesRemaining -= splitSize;</div><div class="line">          &#125;</div><div class="line">          <span class="keyword">if</span> (bytesRemaining != <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">int</span> blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);</div><div class="line">             <span class="comment">//创建切片</span></div><div class="line">             <span class="comment">//切片信息包括文件名，偏移量，大小，位置信息</span></div><div class="line">            splits.add(makeSplit(path, </div><div class="line">length-bytesRemaining, bytesRemaining,</div><div class="line">                 blkLocations[blkIndex].getHosts(),</div><div class="line">             blkLocations[blkIndex].getCachedHosts()));</div><div class="line">          &#125;</div><div class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">// not splitable</span></div><div class="line">         ……</div><div class="line">        &#125;</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="comment">//Create empty hosts array for zero length files</span></div><div class="line">        ……</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    ……</div><div class="line">    <span class="keyword">return</span> splits;</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"> ……</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">conf.setInt(MRJobConfig.NUM_MAPS, maps);</div><div class="line">      LOG.info(<span class="string">"number of splits:"</span> + maps);</div><div class="line">      ……</div><div class="line">      <span class="comment">// Write job file to submit dir</span></div><div class="line">      writeConf(conf, submitJobFile);</div><div class="line">   </div><div class="line">      <span class="comment">// Now, actually submit the job (using the submit name)</span></div><div class="line">      printTokens(jobId, job.getCredentials());</div><div class="line">       <span class="comment">//之前都是提交前的准备，最终提交作业</span></div><div class="line">      status = submitClient.submitJob(</div><div class="line">          jobId, submitJobDir.toString(), job.getCredentials());</div><div class="line"> ……</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>总的来说，客户端做了以下几件事：<br>配置完善<br>检查路径<br>计算split：maps<br>资源提交到HDFS<br>提交任务<br>然后，AppMaster根据split列表信息向ResourceManager申请资源，RS创建container，然后AppMaster启动container，把MapReducer任务放进去。</p>
<h5 id="总结图"><a href="#总结图" class="headerlink" title="总结图"></a>总结图</h5><p><img src="/media/15047859314343.jpg" alt=""></p>
<h5 id="Job类的继承关系"><a href="#Job类的继承关系" class="headerlink" title="Job类的继承关系"></a>Job类的继承关系</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Job</span> <span class="keyword">extends</span> <span class="title">JobContextImpl</span> <span class="keyword">implements</span> <span class="title">JobContext</span></span></div><div class="line"><span class="title">public</span> <span class="title">class</span> <span class="title">JobContextImpl</span> <span class="keyword">implements</span> <span class="title">JobContext</span></div><div class="line"><span class="title">public</span> <span class="title">interface</span> <span class="title">JobContext</span> <span class="keyword">extends</span> <span class="title">MRJobConfig</span></div><div class="line">在<span class="title">interface</span>  <span class="title">MRJobConfig</span>中定义了许多配置的默认值：</div><div class="line"></div><div class="line"><span class="title">MAPTASK</span>内存默认1<span class="title">G</span>（调优可以更改）</div><div class="line"><span class="title">public</span> <span class="title">static</span> <span class="title">final</span> <span class="title">String</span> <span class="title">MAP_MEMORY_MB</span> = <span class="string">"mapreduce.map.memory.mb"</span>;</div><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_MAP_MEMORY_MB = <span class="number">1024</span>;</div><div class="line"></div><div class="line">Reduce内存默认<span class="number">1</span>G，这个默认数值太小，应该调整</div><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String REDUCE_MEMORY_MB = <span class="string">"mapreduce.reduce.memory.mb"</span>;</div><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_REDUCE_MEMORY_MB = <span class="number">1024</span>;</div></pre></td></tr></table></figure>
<h3 id="Map-input"><a href="#Map-input" class="headerlink" title="Map-input"></a>Map-input</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div></pre></td><td class="code"><pre><div class="line">Map类最核心的方法就是run()：</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">    setup(context);</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">while</span> (context.nextKeyValue()) &#123;</div><div class="line">        map(context.getCurrentKey(), context.getCurrentValue(), context);</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      cleanup(context);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">context.nextKeyValue()：map的输入</div><div class="line">context.write(k,v)：map的输出</div><div class="line"></div><div class="line">hadoop-mapreduce-client-core-<span class="number">2.6</span>.5.jar</div><div class="line">org.apache.hadoop.mapred包</div><div class="line">MapTask类中是Map的源码，核心方法：run()</div><div class="line"></div><div class="line"><span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">final</span> JobConf job, </span></span></div><div class="line"><span class="keyword">final</span> TaskUmbilicalProtocol umbilical)</div><div class="line">    <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</div><div class="line">    <span class="keyword">this</span>.umbilical = umbilical;</div><div class="line">    <span class="keyword">if</span> (isMapTask()) &#123;</div><div class="line">      <span class="comment">// If there are no reducers then there won't be any sort. </span></div><div class="line"><span class="comment">// Hence the map</span></div><div class="line">      <span class="comment">// phase will govern the entire attempt's progress.</span></div><div class="line">      <span class="keyword">if</span> (conf.getNumReduceTasks() == <span class="number">0</span>) &#123;</div><div class="line">        mapPhase = getProgress().addPhase(<span class="string">"map"</span>, <span class="number">1.0f</span>);</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="comment">// If there are reducers then the entire attempt's progress will be</span></div><div class="line">        <span class="comment">// split between the map phase (67%) and the sort phase (33%).</span></div><div class="line">         <span class="comment">// map阶段占67%，排序阶段占33%</span></div><div class="line">        mapPhase = getProgress().addPhase(<span class="string">"map"</span>, <span class="number">0.667f</span>);</div><div class="line">        sortPhase  = getProgress().addPhase(<span class="string">"sort"</span>, <span class="number">0.333f</span>);</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    TaskReporter reporter = startReporter(umbilical);</div><div class="line"> </div><div class="line">    <span class="keyword">boolean</span> useNewApi = job.getUseNewMapper();</div><div class="line">    initialize(job, getJobID(), reporter, useNewApi);</div><div class="line">    <span class="comment">// check if it is a cleanupJobTask</span></div><div class="line">……</div><div class="line"><span class="comment">// 如果使用了新版本的API</span></div><div class="line">    <span class="keyword">if</span> (useNewApi) &#123;</div><div class="line">      runNewMapper(job, splitMetaInfo, umbilical, reporter);</div><div class="line"><span class="keyword">private</span> &lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;</div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">runNewMapper</span><span class="params">(<span class="keyword">final</span> JobConf job,</span></span></div><div class="line">                    <span class="keyword">final</span> TaskSplitIndex splitIndex,</div><div class="line">                    <span class="keyword">final</span> TaskUmbilicalProtocol umbilical,</div><div class="line">                    TaskReporter reporter</div><div class="line">                    ) <span class="keyword">throws</span> IOException, ClassNotFoundException,</div><div class="line">                             InterruptedException &#123;</div><div class="line">    <span class="comment">// 1.make a task context so we can get the classes</span></div><div class="line">    org.apache.hadoop.mapreduce.TaskAttemptContext taskContext =</div><div class="line">      <span class="keyword">new</span> org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl(job,</div><div class="line">                                           getTaskID(),reporter);</div><div class="line">    <span class="comment">// 2.make a mapper</span></div><div class="line">org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt; mapper =</div><div class="line">(org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;)</div><div class="line">ReflectionUtils.newInstance(taskContext.getMapperClass(), job);</div><div class="line"><span class="comment">//如果用户设置了，就用用户的，否则用默认的</span></div><div class="line"><span class="comment">//如果使用默认mapper，key直接输出，不进行任何处理 </span></div><div class="line"><span class="keyword">return</span> (Class&lt;? extends Mapper&lt;?,?,?,?&gt;&gt;)</div><div class="line">      conf.getClass(MAP_CLASS_ATTR, Mapper.class);</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">// 3.make the input format</span></div><div class="line">org.apache.hadoop.mapreduce.InputFormat&lt;INKEY,INVALUE&gt; inputFormat =</div><div class="line">(org.apache.hadoop.mapreduce.InputFormat&lt;INKEY,INVALUE&gt;)</div><div class="line">ReflectionUtils.newInstance(taskContext.getInputFormatClass(), job);</div><div class="line"><span class="comment">//如果用户设置了，就用用户的，否则用默认的（TextInputFormat）</span></div><div class="line"></div><div class="line">    <span class="comment">// 4.rebuild the input split</span></div><div class="line">    org.apache.hadoop.mapreduce.InputSplit split = <span class="keyword">null</span>;</div><div class="line">    split = getSplitDetails(<span class="keyword">new</span> Path(splitIndex.getSplitLocation()),</div><div class="line">    splitIndex.getStartOffset());</div><div class="line">    LOG.info(<span class="string">"Processing split: "</span> + split);</div><div class="line">    org.apache.hadoop.mapreduce.RecordReader&lt;INKEY,INVALUE&gt; input =</div><div class="line">      <span class="keyword">new</span> NewTrackingRecordReader&lt;INKEY,INVALUE&gt;</div><div class="line">        (split, inputFormat, reporter, taskContext);</div><div class="line"><span class="comment">// inputFormat 创建了读取器</span></div><div class="line"><span class="keyword">this</span>.real = inputFormat.createRecordReader(split, taskContext);</div><div class="line"><span class="comment">//最终返回的是行读取器</span></div><div class="line"><span class="keyword">return</span> <span class="keyword">new</span> LineRecordReader(recordDelimiterBytes);</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());</div><div class="line">    org.apache.hadoop.mapreduce.RecordWriter output = <span class="keyword">null</span>;</div><div class="line">   </div><div class="line">    <span class="comment">// 5.get an output object</span></div><div class="line">   ……</div><div class="line">org.apache.hadoop.mapreduce.MapContext&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;</div><div class="line">mapContext =</div><div class="line"><span class="keyword">new</span> MapContextImpl&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;(job, getTaskID(),input, output,committer,reporter, split);</div><div class="line">org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;.</div><div class="line">Context mapperContext = <span class="keyword">new</span> WrappedMapper&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;().getMapContext(</div><div class="line">              mapContext);</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">MapContextImpl</span><span class="params">(Configuration conf, TaskAttemptID taskid,</span></span></div><div class="line">                          //reader就是上面的input</div><div class="line">                        RecordReader&lt;KEYIN,VALUEIN&gt; reader,</div><div class="line">                        RecordWriter&lt;KEYOUT,VALUEOUT&gt; writer,</div><div class="line">                        OutputCommitter committer,</div><div class="line">                        StatusReporter reporter,</div><div class="line">                        InputSplit split) &#123;</div><div class="line">    <span class="keyword">super</span>(conf, taskid, writer, committer, reporter);</div><div class="line">    <span class="keyword">this</span>.reader = reader;</div><div class="line">    <span class="keyword">this</span>.split = split;</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">    <span class="keyword">return</span> reader.nextKeyValue();</div><div class="line">  &#125;</div><div class="line"><span class="comment">//最终调用了LineRecordReader的nextKeyValue()</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    <span class="keyword">if</span> (key == <span class="keyword">null</span>) &#123;</div><div class="line">      key = <span class="keyword">new</span> LongWritable();</div><div class="line">    &#125;</div><div class="line">    key.set(pos);</div><div class="line">    <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</div><div class="line">      value = <span class="keyword">new</span> Text();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">int</span> newSize = <span class="number">0</span>;</div><div class="line">    <span class="comment">// We always read one extra line, which lies outside the upper</span></div><div class="line">    <span class="comment">// split limit i.e. (end - 1)</span></div><div class="line">    <span class="keyword">while</span> (getFilePosition() &lt;= end || in.needAdditionalRecordAfterSplit()) &#123;</div><div class="line">      <span class="keyword">if</span> (pos == <span class="number">0</span>) &#123;</div><div class="line">        newSize = skipUtfByteOrderMark();</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        newSize = in.readLine(value, maxLineLength, maxBytesToConsume(pos));</div><div class="line">        pos += newSize;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> ((newSize == <span class="number">0</span>) || (newSize &lt; maxLineLength)) &#123;</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// line too long. try again</span></div><div class="line">      LOG.info(<span class="string">"Skipped line of size "</span> + newSize + <span class="string">" at pos "</span> +</div><div class="line">               (pos - newSize));</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (newSize == <span class="number">0</span>) &#123;</div><div class="line">      key = <span class="keyword">null</span>;</div><div class="line">      value = <span class="keyword">null</span>;</div><div class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">  <span class="comment">// 6.输入初始化，准备输入流</span></div><div class="line">      input.initialize(split, mapperContext);</div><div class="line">real.initialize(split, context);</div><div class="line">FileSplit split = (FileSplit) genericSplit;</div><div class="line">Configuration job = context.getConfiguration();</div><div class="line"><span class="keyword">this</span>.maxLineLength = job.getInt(MAX_LINE_LENGTH, Integer.MAX_VALUE);</div><div class="line"><span class="comment">//偏移量</span></div><div class="line">start = split.getStart();</div><div class="line">end = start + split.getLength();</div><div class="line"><span class="keyword">final</span> Path file = split.getPath();</div><div class="line"><span class="comment">// open the file and seek to the start of the split</span></div><div class="line"><span class="keyword">final</span> FileSystem fs = file.getFileSystem(job);</div><div class="line"><span class="comment">//开启流</span></div><div class="line">fileIn = fs.open(file);</div><div class="line">……</div><div class="line"><span class="comment">//设置读取位置</span></div><div class="line">fileIn.seek(start);</div><div class="line">in = <span class="keyword">new</span> UncompressedSplitLineReader(</div><div class="line">fileIn, job, <span class="keyword">this</span>.recordDelimiterBytes, split.getLength());</div><div class="line">filePosition = fileIn;</div><div class="line"><span class="comment">//If this is not the first split, we always throw away first record</span></div><div class="line"><span class="comment">//because we always (except the last split) read one extra line in</span></div><div class="line"><span class="comment">//next() method.</span></div><div class="line"><span class="comment">//判断不是第一个切片时，抛弃第一行，防止数据被切割，第一行由上一个片读</span></div><div class="line"><span class="keyword">if</span> (start != <span class="number">0</span>) &#123;</div><div class="line">    start += in.readLine(<span class="keyword">new</span> Text(), <span class="number">0</span>, maxBytesToConsume(start));</div><div class="line">&#125;</div><div class="line"><span class="keyword">this</span>.pos = start;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">      <span class="comment">// 7.执行mapper的run()</span></div><div class="line">      mapper.run(mapperContext);</div><div class="line">      mapPhase.complete();</div><div class="line">      setPhase(TaskStatus.Phase.SORT);</div><div class="line">      statusUpdate(umbilical);</div><div class="line">      <span class="comment">// 8.关闭input</span></div><div class="line">      input.close();</div><div class="line">      input = <span class="keyword">null</span>;</div><div class="line">      output.close(mapperContext);</div><div class="line">      output = <span class="keyword">null</span>;</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      closeQuietly(input);</div><div class="line">      closeQuietly(output, mapperContext);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      runOldMapper(job, splitMetaInfo, umbilical, reporter);</div><div class="line">    &#125;</div><div class="line">    done(umbilical, reporter);</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>反射mapper<br>准备input来读数据<br>        考虑本地读取，通过seek()设置<br>考虑一行数据切割问题，非第一个split首行放弃，上一个split多处理一行<br>    pos更新<br>    执行map()<br>input的nextKeyValue()，更新key和value<br>通过getCurrentKey()和getCurrentValue()取到更新后的kv，传参给map()</p>
<h5 id="总结图-1"><a href="#总结图-1" class="headerlink" title="总结图"></a>总结图</h5><p><img src="/media/2-1.png" alt=""></p>
<h3 id="Map-output"><a href="#Map-output" class="headerlink" title="Map-output"></a>Map-output</h3><h4 id="环形缓冲区"><a href="#环形缓冲区" class="headerlink" title="环形缓冲区"></a>环形缓冲区</h4><p>Map输出数据到磁盘时，会先写到内存，当内存中的数据占到一定比例，再一次性把这些数据溢写到磁盘，这个缓存区默认大小为100M，假设以下内存是Map的缓冲区<br><img src="/media/15047877612658.jpg" alt=""><br>实际上Map会把这段内存当作逻辑上的环形缓冲区来使用<br><img src="/media/15047888584939.jpg" alt=""><br>Map开始写数据到环形缓存区<br><img src="/media/15047889247578.jpg" alt=""><br><img src="/media/15047889425546.jpg" alt=""><br>在真实的物理内存中，数据是这么分布的：<br><img src="/media/15047889833790.jpg" alt=""></p>
<h4 id="MapTask类"><a href="#MapTask类" class="headerlink" title="MapTask类"></a>MapTask类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// get an output object</span></div><div class="line"><span class="keyword">if</span> (job.getNumReduceTasks() == <span class="number">0</span>) &#123;<span class="comment">// 如果reduce数量为0</span></div><div class="line"><span class="comment">//reduce数量可以由程序控制，有多个key设置多个reduce才有意义</span></div><div class="line">output =</div><div class="line">    <span class="keyword">new</span> NewDirectOutputCollector(taskContext, job, umbilical, reporter);</div><div class="line">&#125; <span class="keyword">else</span> &#123;</div><div class="line"> output = <span class="keyword">new</span> NewOutputCollector(taskContext, job, umbilical, reporter);</div><div class="line">&#125;</div><div class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</div><div class="line">NewOutputCollector(</div><div class="line">org.apache.hadoop.mapreduce.JobContext jobContext,</div><div class="line">                       JobConf job,</div><div class="line">                       TaskUmbilicalProtocol umbilical,</div><div class="line">                       TaskReporter reporter</div><div class="line">                       ) <span class="keyword">throws</span> IOException, ClassNotFoundException &#123;</div><div class="line">       <span class="comment">// 创建一个容器</span></div><div class="line">      collector = createSortingCollector(job, reporter);</div><div class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</div><div class="line">  <span class="keyword">private</span> &lt;KEY, VALUE&gt; <span class="function">MapOutputCollector&lt;KEY, VALUE&gt;</span></div><div class="line">     <span class="title">createSortingCollector</span><span class="params">(JobConf job, TaskReporter reporter)</span></div><div class="line">    <span class="keyword">throws</span> IOException, ClassNotFoundException &#123;</div><div class="line">    MapOutputCollector.Context context =</div><div class="line">      <span class="keyword">new</span> MapOutputCollector.Context(<span class="keyword">this</span>, job, reporter);</div><div class="line">Class&lt;?&gt;[] collectorClasses = job.getClasses(</div><div class="line">  <span class="comment">// 如果自定义一个输出类的逻辑，就使用自定义的</span></div><div class="line">  <span class="comment">// 否则使用默认的MapOutputBuffer，即环形缓存区</span></div><div class="line">      JobContext.MAP_OUTPUT_COLLECTOR_CLASS_ATTR, MapOutputBuffer.class);</div><div class="line">     ……</div><div class="line">         <span class="comment">// 初始化</span></div><div class="line">        collector.init(context);</div><div class="line"><span class="comment">//sanity checks，都是调优点</span></div><div class="line"><span class="keyword">final</span> <span class="keyword">float</span> spillper =</div><div class="line"><span class="comment">//进行溢写的阈值</span></div><div class="line"> job.getFloat(JobContext.MAP_SORT_SPILL_PERCENT, (<span class="keyword">float</span>)<span class="number">0.8</span>);</div><div class="line"><span class="comment">//环形缓冲区大小</span></div><div class="line"><span class="keyword">final</span> <span class="keyword">int</span> sortmb = job.getInt(JobContext.IO_SORT_MB, <span class="number">100</span>);</div><div class="line">……</div><div class="line"></div><div class="line"><span class="comment">// 溢写到磁盘，默认采用快速排序</span></div><div class="line">sorter = ReflectionUtils.newInstance(job.getClass(<span class="string">"map.sort.class"</span>,</div><div class="line">         QuickSort.class, IndexedSorter.class), job);</div><div class="line"></div><div class="line"><span class="comment">// 设置缓存区写数据和写索引之间的临界点（赤道）</span></div><div class="line"><span class="keyword">int</span> maxMemUsage = sortmb &lt;&lt; <span class="number">20</span>;</div><div class="line">maxMemUsage -= maxMemUsage % METASIZE;</div><div class="line">kvbuffer = <span class="keyword">new</span> <span class="keyword">byte</span>[maxMemUsage];</div><div class="line">bufvoid = kvbuffer.length;</div><div class="line">kvmeta = ByteBuffer.wrap(kvbuffer)</div><div class="line">     .order(ByteOrder.nativeOrder())</div><div class="line">     .asIntBuffer();</div><div class="line">setEquator(<span class="number">0</span>);</div><div class="line">bufstart = bufend = bufindex = equator;</div><div class="line">kvstart = kvend = kvindex;</div><div class="line">……</div><div class="line"><span class="comment">// k/v serialization</span></div><div class="line"><span class="comment">// 获得比较器</span></div><div class="line">comparator = job.getOutputKeyComparator();</div><div class="line"><span class="comment">// 先取自定义的比较器，没有就取MapOutputKeyClass的K的比较器</span></div><div class="line"><span class="comment">// 比如Text按照字典序排序</span></div><div class="line"><span class="comment">// 如果有自定义的，必须实现RawComparator接口</span></div><div class="line"><span class="function"><span class="keyword">public</span> RawComparator <span class="title">getOutputKeyComparator</span><span class="params">()</span> </span>&#123;</div><div class="line">    Class&lt;? extends RawComparator&gt; theClass = getClass(</div><div class="line">     JobContext.KEY_COMPARATOR, <span class="keyword">null</span>, RawComparator.class);</div><div class="line">    <span class="keyword">if</span> (theClass != <span class="keyword">null</span>)</div><div class="line">      <span class="keyword">return</span> ReflectionUtils.newInstance(theClass, <span class="keyword">this</span>);</div><div class="line"><span class="keyword">return</span> WritableComparator.get(getMapOutputKeyClass().asSubclass(</div><div class="line">WritableComparable.class), <span class="keyword">this</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// combiner</span></div><div class="line"><span class="comment">// 在map端对同一个key的内容进行合并</span></div><div class="line"></div><div class="line"><span class="comment">// 环形缓存区的数据到达80%后，会开启新线程进行排序和溢写</span></div><div class="line"><span class="comment">// 调优点：缓存区的数据溢写3次后生成3个小文件，会对这3个小文件再进行combiner，这个数字可以调整</span></div><div class="line">minSpillsForCombine = job.getInt(JobContext.MAP_COMBINE_MIN_SPILLS, <span class="number">3</span>);</div><div class="line">spillThread.setDaemon(<span class="keyword">true</span>);</div><div class="line">spillThread.setName(<span class="string">"SpillThread"</span>);</div><div class="line">spillLock.lock();</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">spillThread.start();</div><div class="line">sortAndSpill();</div><div class="line"><span class="comment">// sort使用快速排序，然后combiner合并，然后溢写到磁盘，产生一个小文件</span></div><div class="line">sorter.sort(MapOutputBuffer.<span class="keyword">this</span>, mstart, mend, reporter);</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">    <span class="keyword">while</span> (!spillThreadRunning) &#123;</div><div class="line">        spillDone.await();</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">……        </div><div class="line"><span class="keyword">return</span> collector;</div><div class="line">……</div><div class="line">Collector初始化完毕</div><div class="line"></div><div class="line"></div><div class="line">      <span class="comment">// collector创建成功</span></div><div class="line"></div><div class="line">      <span class="comment">// 分区数量等于reduce数量</span></div><div class="line">      partitions = jobContext.getNumReduceTasks();</div><div class="line">      <span class="keyword">if</span> (partitions &gt; <span class="number">1</span>) &#123;</div><div class="line">       <span class="comment">// 生成分区器，但还没有使用</span></div><div class="line">        partitioner = (org.apache.hadoop.mapreduce.Partitioner&lt;K,V&gt;)</div><div class="line">ReflectionUtils.newInstance(jobContext.getPartitionerClass(), job);</div><div class="line"><span class="comment">// 如果自定义了分区器的逻辑，就使用自定义的，否则使用HashPartitioner</span></div><div class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</div><div class="line"><span class="keyword">public</span> Class&lt;? extends Partitioner&lt;?,?&gt;&gt; getPartitionerClass()</div><div class="line">     <span class="keyword">throws</span> ClassNotFoundException &#123;</div><div class="line"><span class="keyword">return</span> (Class&lt;? extends Partitioner&lt;?,?&gt;&gt;)</div><div class="line">conf.getClass(PARTITIONER_CLASS_ATTR, HashPartitioner.class);</div><div class="line">&#125;</div><div class="line">HashPartitioner：</div><div class="line"><span class="comment">// 返回K的hashCode对reduce数量取模后的整数，</span></div><div class="line"><span class="comment">// 弊端：可能造成数据倾斜</span></div><div class="line"><span class="comment">// 所以partitioner是一个调优的地方</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(K key, V value,</span></span></div><div class="line">                          <span class="keyword">int</span> numReduceTasks) &#123;</div><div class="line"> <span class="keyword">return</span> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// 所以partitions = 1，返回0</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        partitioner = <span class="keyword">new</span> org.apache.hadoop.mapreduce.Partitioner&lt;K,V&gt;() &#123;</div><div class="line">          <span class="meta">@Override</span></div><div class="line">          <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(K key, V value, <span class="keyword">int</span> numPartitions)</span> </span>&#123;</div><div class="line">            <span class="keyword">return</span> partitions - <span class="number">1</span>;</div><div class="line">          &#125;</div><div class="line">        &#125;;</div><div class="line">      &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// 分区器创建成功</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// output创建成功</span></div><div class="line"></div><div class="line">org.apache.hadoop.mapreduce.MapContext&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;</div><div class="line">    mapContext =</div><div class="line">      <span class="keyword">new</span> MapContextImpl&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;(</div><div class="line">job, </div><div class="line">getTaskID(),</div><div class="line">         input, </div><div class="line">output,</div><div class="line">         committer,</div><div class="line">         reporter, </div><div class="line">split);</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">MapContextImpl</span><span class="params">(Configuration conf, TaskAttemptID taskid,</span></span></div><div class="line">                        RecordReader&lt;KEYIN,VALUEIN&gt; reader,</div><div class="line">                        RecordWriter&lt;KEYOUT,VALUEOUT&gt; writer,</div><div class="line">                        OutputCommitter committer,</div><div class="line">                        StatusReporter reporter,</div><div class="line">                        InputSplit split) &#123;</div><div class="line">    <span class="keyword">super</span>(conf, taskid, writer, committer, reporter);</div><div class="line">    <span class="keyword">this</span>.reader = reader;</div><div class="line">    <span class="keyword">this</span>.split = split;</div><div class="line">&#125;</div><div class="line">MapContextImpl的父类：</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">TaskInputOutputContextImpl</span><span class="params">(</span></span></div><div class="line">Configuration conf, </div><div class="line">TaskAttemptID taskid,</div><div class="line">RecordWriter&lt;KEYOUT,VALUEOUT&gt; output,</div><div class="line">OutputCommitter committer,</div><div class="line">StatusReporter reporter) &#123;</div><div class="line">    <span class="keyword">super</span>(conf, taskid, reporter);</div><div class="line">    <span class="keyword">this</span>.output = output;</div><div class="line">    <span class="keyword">this</span>.committer = committer;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(KEYOUT key, VALUEOUT value</span></span></div><div class="line">                    ) <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">    output.write(key, value);</div><div class="line">&#125;</div><div class="line"><span class="comment">// 这个write()调用了下面的方法： </span></div><div class="line"><span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(K key, V value)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">      collector.collect(key, value,</div><div class="line">                  partitioner.getPartition(key, value, partitions));</div><div class="line">&#125;</div><div class="line"><span class="comment">// collector()就是执行collector的初始化过程</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// 关闭output</span></div><div class="line">output.close(mapperContext);</div><div class="line"><span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">(TaskAttemptContext context</span></span></div><div class="line">                      ) <span class="keyword">throws</span> IOException,InterruptedException &#123;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        collector.flush();</div><div class="line">      &#125; <span class="keyword">catch</span> (ClassNotFoundException cnf) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"can't find class "</span>, cnf);</div><div class="line">      &#125;</div><div class="line">      collector.close();</div><div class="line">&#125;</div><div class="line"><span class="comment">// 把缓存区中没有达到阈值的数据也写到磁盘</span></div><div class="line">sortAndSpill();</div><div class="line"><span class="comment">// 合并文件</span></div><div class="line">mergeParts();</div><div class="line"><span class="comment">// 如果溢写次数大于3（可修改），触发combiner</span></div><div class="line"><span class="keyword">if</span> (combinerRunner == <span class="keyword">null</span> || numSpills &lt; minSpillsForCombine) &#123;</div><div class="line">            Merger.writeFile(kvIter, writer, reporter, job);</div><div class="line">          &#125; <span class="keyword">else</span> &#123;</div><div class="line">            combineCollector.setWriter(writer);</div><div class="line">            combinerRunner.combine(kvIter, combineCollector);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h5 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">output</div><div class="line">collector = createSortingCollector(job, reporter);</div><div class="line">	JobContext.MAP_OUTPUT_COLLECTOR_CLASS_ATTR, MapOutputBuffer.class);</div><div class="line">	collector.init(context)</div><div class="line">		sortmb = job.getInt(JobContext.IO_SORT_MB, <span class="number">100</span>);</div><div class="line">spillper = job.getFloat(JobContext.MAP_SORT_SPILL_PERCENT, (<span class="keyword">float</span>)<span class="number">0.8</span>)</div><div class="line">sorter = ReflectionUtils.newInstance(job.getClass(<span class="string">"map.sort.class"</span>,</div><div class="line">            				QuickSort.class, IndexedSorter.class), job);</div><div class="line">comparator = job.getOutputKeyComparator();</div><div class="line">combinerRunner = CombinerRunner.create(job, getTaskID(), </div><div class="line">                            combineInputCounter,reporter, <span class="keyword">null</span>);</div><div class="line">minSpillsForCombine = job.getInt(JobContext.MAP_COMBINE_MIN_SPILLS, <span class="number">3</span>);</div><div class="line">spillThread.start();</div><div class="line">sortAndSpill();</div><div class="line">partitions = jobContext.getNumReduceTasks();</div><div class="line">partitioner = (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks 或者自定义</div><div class="line">output.write(key, value);</div><div class="line">	collector.collect(key, value,partitioner.getPartition(key, value, partitions));</div><div class="line">output.close(mapperContext);</div><div class="line">	collector.flush();</div><div class="line">		sortAndSpill();</div><div class="line">		mergeParts();</div></pre></td></tr></table></figure>
<h5 id="总结图-2"><a href="#总结图-2" class="headerlink" title="总结图"></a>总结图</h5><p><img src="/media/3-1.png" alt=""></p>
<h4 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h4><h5 id="ReduceTask"><a href="#ReduceTask" class="headerlink" title="ReduceTask"></a>ReduceTask</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// ======================run()方法作为入口=============================</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(JobConf job, <span class="keyword">final</span> TaskUmbilicalProtocol umbilical)</span></span></div><div class="line">    <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</div><div class="line">    job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());</div><div class="line"><span class="keyword">if</span> (isMapOrReduce()) &#123;</div><div class="line">       <span class="comment">// reduce 3 个阶段：copy、sort、reduce</span></div><div class="line">      copyPhase = getProgress().addPhase(<span class="string">"copy"</span>);</div><div class="line">      sortPhase  = getProgress().addPhase(<span class="string">"sort"</span>);</div><div class="line">      reducePhase = getProgress().addPhase(<span class="string">"reduce"</span>);</div><div class="line">&#125;</div><div class="line">……</div><div class="line"><span class="comment">// =============以下代码是copy阶段（shuffle）=========================</span></div><div class="line"><span class="comment">// Initialize the codec</span></div><div class="line">    codec = initCodec();</div><div class="line">    RawKeyValueIterator rIter = <span class="keyword">null</span>;</div><div class="line">    ShuffleConsumerPlugin shuffleConsumerPlugin = <span class="keyword">null</span>;</div><div class="line">   </div><div class="line">    Class combinerClass = conf.getCombinerClass();</div><div class="line">    CombineOutputCollector combineCollector =</div><div class="line">      (<span class="keyword">null</span> != combinerClass) ?</div><div class="line">     <span class="keyword">new</span> CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : <span class="keyword">null</span>;</div><div class="line">    Class&lt;? extends ShuffleConsumerPlugin&gt; clazz =</div><div class="line">          job.getClass(MRConfig.SHUFFLE_CONSUMER_PLUGIN, Shuffle.class, ShuffleConsumerPlugin.class);</div><div class="line">                       </div><div class="line">    shuffleConsumerPlugin = ReflectionUtils.newInstance(clazz, job);</div><div class="line">    LOG.info(<span class="string">"Using ShuffleConsumerPlugin: "</span> + shuffleConsumerPlugin);</div><div class="line">    ShuffleConsumerPlugin.Context shuffleContext =</div><div class="line">      <span class="keyword">new</span> ShuffleConsumerPlugin.Context(getTaskID(), job, FileSystem.getLocal(job), umbilical,</div><div class="line">                  <span class="keyword">super</span>.lDirAlloc, reporter, codec,</div><div class="line">                  combinerClass, combineCollector,</div><div class="line">                  spilledRecordsCounter, reduceCombineInputCounter,</div><div class="line">                  shuffledMapsCounter,</div><div class="line">                  reduceShuffleBytes, failedShuffleCounter,</div><div class="line">                  mergedMapOutputsCounter,</div><div class="line">                  taskStatus, copyPhase, sortPhase, <span class="keyword">this</span>,</div><div class="line">                  mapOutputFile, localMapFiles);</div><div class="line">    shuffleConsumerPlugin.init(shuffleContext);</div><div class="line">  <span class="comment">// 得到迭代器</span></div><div class="line">rIter = shuffleConsumerPlugin.run();</div><div class="line"><span class="comment">// ===========================copy阶段结束==========================</span></div><div class="line"></div><div class="line"><span class="comment">//===========================准备比较器=============================</span></div><div class="line">RawComparator comparator = job.getOutputValueGroupingComparator();</div><div class="line"><span class="function"><span class="keyword">public</span> RawComparator <span class="title">getOutputValueGroupingComparator</span><span class="params">()</span> </span>&#123;</div><div class="line">    Class&lt;? extends RawComparator&gt; theClass = getClass(</div><div class="line">      JobContext.GROUP_COMPARATOR_CLASS, <span class="keyword">null</span>, RawComparator.class);</div><div class="line"><span class="keyword">if</span> (theClass == <span class="keyword">null</span>) &#123;</div><div class="line">  <span class="comment">// 如果没有自定义，调用这个方法</span></div><div class="line">  <span class="comment">/*</span></div><div class="line">Map 端取排序比较器的顺序：</div><div class="line">1.	取自定义的排序比较器</div><div class="line">2.	取key自带的比较器</div><div class="line">Reduce端取比较器的顺序</div><div class="line">1.	取自定义的分组比较器</div><div class="line">2.	取自定义的排序比较器</div><div class="line">3.	取key自带的比较器</div><div class="line">*/</div><div class="line">      <span class="keyword">return</span> getOutputKeyComparator();</div><div class="line">    &#125;</div><div class="line">   </div><div class="line">    <span class="keyword">return</span> ReflectionUtils.newInstance(theClass, <span class="keyword">this</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">//===================== 准备比较器 结束=============================</span></div><div class="line"></div><div class="line"><span class="comment">//===================== runNewReducer =============================</span></div><div class="line">    runNewReducer(job, umbilical, reporter, rIter, comparator,</div><div class="line">                    keyClass, valueClass);</div><div class="line">     </div><div class="line"><span class="comment">//创建reducer</span></div><div class="line">reducer = ReflectionUtils.newInstance(taskContext.getReducerClass(), job);</div><div class="line"><span class="comment">//创建reducerContext（传入了迭代器和比较器）</span></div><div class="line">reducerContext = createReduceContext(reducer, job, getTaskID(),</div><div class="line">rIter, reduceInputKeyCounter,reduceInputValueCounter,</div><div class="line">trackedRW,committer,reporter, comparator,keyClass,</div><div class="line">                                               valueClass);</div><div class="line">reduceContext =</div><div class="line">      <span class="keyword">new</span> ReduceContextImpl&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;(</div><div class="line">job, taskId,rIter,inputKeyCounter,inputValueCounter,output,</div><div class="line">committer,reporter,comparator,keyClass,valueClass);</div><div class="line"><span class="comment">// 使用了ReduceContextImpl类</span></div><div class="line"></div><div class="line">其中有getCurrentKey(), context.getValues()等方法</div><div class="line">Reduce类调用的方法来自这里</div><div class="line"><span class="comment">// =====================ReduceContextImpl start=================</span></div><div class="line"><span class="keyword">private</span> KEYIN key;                        <span class="comment">// current key</span></div><div class="line"><span class="keyword">private</span> VALUEIN value;                    <span class="comment">// current value</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> firstValue = <span class="keyword">false</span>;       <span class="comment">// first value in key</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> nextKeyIsSame = <span class="keyword">false</span>;    <span class="comment">// more w/ this key</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> hasMore;                  <span class="comment">// more in file</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">ReduceContextImpl</span><span class="params">(Configuration conf, </span></span></div><div class="line">TaskAttemptID taskid,</div><div class="line">                           RawKeyValueIterator input,</div><div class="line">                           Counter inputKeyCounter,</div><div class="line">                           Counter inputValueCounter,</div><div class="line">                           RecordWriter&lt;KEYOUT,VALUEOUT&gt; output,</div><div class="line">                           OutputCommitter committer,</div><div class="line">                           StatusReporter reporter,</div><div class="line">                           RawComparator&lt;KEYIN&gt; comparator,</div><div class="line">                           Class&lt;KEYIN&gt; keyClass,</div><div class="line">                           Class&lt;VALUEIN&gt; valueClass</div><div class="line">                          ) </div><div class="line"><span class="keyword">throws</span> InterruptedException, IOException&#123;</div><div class="line">    <span class="keyword">super</span>(conf, taskid, output, committer, reporter);</div><div class="line">    <span class="keyword">this</span>.input = input;</div><div class="line">    <span class="keyword">this</span>.inputKeyCounter = inputKeyCounter;</div><div class="line">    <span class="keyword">this</span>.inputValueCounter = inputValueCounter;</div><div class="line">    <span class="keyword">this</span>.comparator = comparator;</div><div class="line">    <span class="keyword">this</span>.serializationFactory = <span class="keyword">new</span> SerializationFactory(conf);</div><div class="line">    <span class="keyword">this</span>.keyDeserializer = serializationFactory.getDeserializer(keyClass);</div><div class="line">    <span class="keyword">this</span>.keyDeserializer.open(buffer); <span class="comment">// 和buffer做了绑定</span></div><div class="line">    <span class="keyword">this</span>.valueDeserializer = serializationFactory.getDeserializer(valueClass);</div><div class="line">    <span class="keyword">this</span>.valueDeserializer.open(buffer);</div><div class="line">    hasMore = input.next();</div><div class="line">    <span class="keyword">this</span>.keyClass = keyClass;</div><div class="line">    <span class="keyword">this</span>.valueClass = valueClass;</div><div class="line">    <span class="keyword">this</span>.conf = conf;</div><div class="line">    <span class="keyword">this</span>.taskid = taskid;</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException,InterruptedException </span>&#123;</div><div class="line">    <span class="keyword">while</span> (hasMore &amp;&amp; nextKeyIsSame) &#123;</div><div class="line">      nextKeyValue();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (hasMore) &#123;</div><div class="line">      <span class="keyword">if</span> (inputKeyCounter != <span class="keyword">null</span>) &#123;</div><div class="line">        inputKeyCounter.increment(<span class="number">1</span>);</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">return</span> nextKeyValue();</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">    <span class="keyword">if</span> (!hasMore) &#123;</div><div class="line">      key = <span class="keyword">null</span>;</div><div class="line">      value = <span class="keyword">null</span>;</div><div class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    &#125;</div><div class="line">    firstValue = !nextKeyIsSame;</div><div class="line">    DataInputBuffer nextKey = input.getKey();</div><div class="line">    currentRawKey.set(nextKey.getData(), nextKey.getPosition(),</div><div class="line">                   nextKey.getLength() - nextKey.getPosition());</div><div class="line">    buffer.reset(currentRawKey.getBytes(), <span class="number">0</span>, currentRawKey.getLength());</div><div class="line">    <span class="comment">// 得到 Key/Value</span></div><div class="line">    key = keyDeserializer.deserialize(key);</div><div class="line">    DataInputBuffer nextVal = input.getValue();</div><div class="line">    buffer.reset(nextVal.getData(), nextVal.getPosition(), nextVal.getLength()- nextVal.getPosition());</div><div class="line">    value = valueDeserializer.deserialize(value);</div><div class="line">    currentKeyLength = nextKey.getLength() - nextKey.getPosition();</div><div class="line">    currentValueLength = nextVal.getLength() - nextVal.getPosition();</div><div class="line">    <span class="keyword">if</span> (isMarked) &#123;</div><div class="line">      backupStore.write(nextKey, nextVal);</div><div class="line">    &#125;</div><div class="line">    hasMore = input.next();</div><div class="line">    <span class="keyword">if</span> (hasMore) &#123;</div><div class="line">      nextKey = input.getKey();</div><div class="line">       <span class="comment">// 判断下一个key与当前key是否相同</span></div><div class="line">      nextKeyIsSame = comparator.compare(</div><div class="line">currentRawKey.getBytes(), <span class="number">0</span>,</div><div class="line">                                     currentRawKey.getLength(),</div><div class="line">                                     nextKey.getData(),</div><div class="line">                                     nextKey.getPosition(),</div><div class="line">                      nextKey.getLength() - nextKey.getPosition()</div><div class="line">                                         ) == <span class="number">0</span>;</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      nextKeyIsSame = <span class="keyword">false</span>;</div><div class="line">    &#125;</div><div class="line">    inputValueCounter.increment(<span class="number">1</span>);</div><div class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="comment">// 这个方法直接返回key，那就要求key是实时更新的，nextKeyValue()可以保证同时更新key和value</span></div><div class="line"><span class="function"><span class="keyword">public</span> KEYIN <span class="title">getCurrentKey</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> key;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// 通过内部类定义了迭代器供reduce使用</span></div><div class="line"><span class="keyword">protected</span> <span class="class"><span class="keyword">class</span> <span class="title">ValueIterable</span> <span class="keyword">implements</span> <span class="title">Iterable</span>&lt;<span class="title">VALUEIN</span>&gt; </span>&#123;</div><div class="line">    <span class="keyword">private</span> ValueIterator iterator = <span class="keyword">new</span> ValueIterator();</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> Iterator&lt;VALUEIN&gt; <span class="title">iterator</span><span class="params">()</span> </span>&#123;</div><div class="line">      <span class="keyword">return</span> iterator;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// 定义了迭代器的通用方法</span></div><div class="line"><span class="keyword">protected</span> <span class="class"><span class="keyword">class</span> <span class="title">ValueIterator</span> <span class="keyword">implements</span> <span class="title">ReduceContext</span>.<span class="title">ValueIterator</span>&lt;<span class="title">VALUEIN</span>&gt; </span>&#123;</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">if</span> (inReset &amp;&amp; backupStore.hasNext()) &#123;</div><div class="line">          <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">        &#125;</div><div class="line">      &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"hasNext failed"</span>, e);</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">return</span> firstValue || nextKeyIsSame;</div><div class="line">&#125;</div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> VALUEIN <span class="title">next</span><span class="params">()</span> </span>&#123;</div><div class="line">......</div><div class="line"><span class="keyword">if</span> (!nextKeyIsSame) &#123;</div><div class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchElementException(<span class="string">"iterate past last value"</span>);</div><div class="line">        &#125;</div><div class="line">      <span class="comment">// otherwise, go to the next key/value pair</span></div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        nextKeyValue();</div><div class="line">        <span class="keyword">return</span> value;</div><div class="line">      &#125; <span class="keyword">catch</span> (IOException ie) &#123;</div><div class="line">    ......      </div><div class="line">      &#125;</div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// =====================ReduceContextImpl end=================</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">reducer.run(reducerContext);</div><div class="line"><span class="comment">// 1. setup()</span></div><div class="line"><span class="comment">// 2. run()</span></div><div class="line"><span class="comment">// 3. cleanup()</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">    setup(context);</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">while</span> (context.nextKey()) &#123;</div><div class="line"><span class="comment">// 3. Map端是context.nextKeyValue()</span></div><div class="line">   reduce(context.getCurrentKey(), context.getValues(), context);</div><div class="line">        <span class="comment">// If a back up store is used, reset it</span></div><div class="line">        Iterator&lt;VALUEIN&gt; iter = context.getValues().iterator();</div><div class="line">        <span class="keyword">if</span>(iter <span class="keyword">instanceof</span> ReduceContext.ValueIterator) &#123;</div><div class="line">          ((ReduceContext.ValueIterator&lt;VALUEIN&gt;)iter)</div><div class="line">.resetBackupStore(); </div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      cleanup(context);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">//===================== runNewReducer 结束==========================</span></div></pre></td></tr></table></figure>
<h5 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h5><p>Reduce有3个阶段</p>
<ol>
<li>Shuffle<br>shuffleConsumerPlugin.init(shuffleContext);<br>rIter = shuffleConsumerPlugin.run();</li>
<li>Sort</li>
<li>Reduce<br>runNewReducer()<br>创建reducer<br>创建reducerContext, new ReduceContextImpl对象<br>ReduceContextImpl<br>  getCurrentKey()<br>  nextKey()<pre><code>nextKeyValue() //同时更新key和value
</code></pre>  内部类ValueIterable<pre><code>ValueIterator iterator = new ValueIterator();
</code></pre>  内部类ValueIterator<pre><code>hasNext()
next()
    nextKeyValue()//同时更新key和value
</code></pre>reducer.run(reducerContext);<br>  while (context.nextKey())<pre><code>reduce(context.getCurrentKey(), context.getValues(), context);
    Iterator&lt;VALUEIN&gt; iter = context.getValues().iterator();
</code></pre>总结图<br><img src="/media/4.png" alt="4"><h3 id="Hadoop案例：Weather"><a href="#Hadoop案例：Weather" class="headerlink" title="Hadoop案例：Weather"></a>Hadoop案例：Weather</h3>需求：找出每个月气温最高的2天，测试数据如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">1949-10-01 14:21:02	34c</div><div class="line">1949-10-01 19:21:02	38c</div><div class="line">1949-10-02 14:01:02	36c</div><div class="line">1950-01-01 11:21:02	32c</div><div class="line">1950-10-01 12:21:02	37c</div><div class="line">1951-12-01 12:21:02	23c</div><div class="line">1950-10-02 12:21:02	41c</div><div class="line">1950-10-03 12:21:02	27c</div><div class="line">1951-07-01 12:21:02	45c</div><div class="line">1951-07-02 12:21:02	46c</div><div class="line">1951-07-03 12:21:03	47c</div></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="自定义封装类"><a href="#自定义封装类" class="headerlink" title="自定义封装类"></a>自定义封装类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.sxt.hadoop.mapreduce.weather;</div><div class="line"><span class="keyword">import</span> java.io.DataInput;</div><div class="line"><span class="keyword">import</span> java.io.DataOutput;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Weather</span> <span class="keyword">implements</span> <span class="title">WritableComparable</span>&lt;<span class="title">Weather</span>&gt;</span>&#123;</div><div class="line">     </div><div class="line">     <span class="keyword">private</span> <span class="keyword">int</span> year = <span class="number">0</span>;</div><div class="line">     <span class="keyword">private</span> <span class="keyword">int</span> month = <span class="number">0</span>;</div><div class="line">     <span class="keyword">private</span> <span class="keyword">int</span> day = <span class="number">0</span>;</div><div class="line">     <span class="keyword">private</span> <span class="keyword">int</span> temperature = <span class="number">0</span>;</div><div class="line">     </div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getYear</span><span class="params">()</span> </span>&#123;</div><div class="line">         <span class="keyword">return</span> year;</div><div class="line">     &#125;</div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setYear</span><span class="params">(<span class="keyword">int</span> year)</span> </span>&#123;</div><div class="line">         <span class="keyword">this</span>.year = year;</div><div class="line">     &#125;</div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getMonth</span><span class="params">()</span> </span>&#123;</div><div class="line">         <span class="keyword">return</span> month;</div><div class="line">     &#125;</div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMonth</span><span class="params">(<span class="keyword">int</span> month)</span> </span>&#123;</div><div class="line">         <span class="keyword">this</span>.month = month;</div><div class="line">     &#125;</div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getDay</span><span class="params">()</span> </span>&#123;</div><div class="line">         <span class="keyword">return</span> day;</div><div class="line">     &#125;</div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDay</span><span class="params">(<span class="keyword">int</span> day)</span> </span>&#123;</div><div class="line">         <span class="keyword">this</span>.day = day;</div><div class="line">     &#125;</div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getTemperature</span><span class="params">()</span> </span>&#123;</div><div class="line">         <span class="keyword">return</span> temperature;</div><div class="line">     &#125;</div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setTemperature</span><span class="params">(<span class="keyword">int</span> temperature)</span> </span>&#123;</div><div class="line">         <span class="keyword">this</span>.temperature = temperature;</div><div class="line">     &#125;</div><div class="line">     <span class="meta">@Override</span></div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">         out.writeInt(year);</div><div class="line">         out.writeInt(month);</div><div class="line">         out.writeInt(day);</div><div class="line">         out.writeInt(temperature);</div><div class="line">     &#125;</div><div class="line">     <span class="meta">@Override</span></div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">         <span class="keyword">this</span>.year = in.readInt();</div><div class="line">         <span class="keyword">this</span>.month = in.readInt();</div><div class="line">         <span class="keyword">this</span>.day = in.readInt();</div><div class="line">         <span class="keyword">this</span>.temperature = in.readInt();</div><div class="line">     &#125;</div><div class="line">     <span class="meta">@Override</span></div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(Weather w)</span> </span>&#123;</div><div class="line">         <span class="keyword">int</span> c1 = Integer.compare(<span class="keyword">this</span>.year, w.getYear());</div><div class="line">         <span class="keyword">if</span>(c1 == <span class="number">0</span>) &#123;</div><div class="line">              <span class="keyword">int</span> c2 = Integer.compare(<span class="keyword">this</span>.month, w.getMonth());</div><div class="line">              <span class="keyword">if</span>(c2 == <span class="number">0</span>) &#123;</div><div class="line">                  <span class="keyword">int</span> c3 = Integer.compare(<span class="keyword">this</span>.day, w.getDay());</div><div class="line">                  <span class="keyword">if</span>(c3 == <span class="number">0</span>) &#123;</div><div class="line">                       <span class="keyword">return</span> Integer.compare(</div><div class="line"><span class="keyword">this</span>.temperature, w.getTemperature());</div><div class="line">                  &#125;<span class="keyword">else</span> &#123;</div><div class="line">                       <span class="keyword">return</span> c3;</div><div class="line">                  &#125;</div><div class="line">              &#125;<span class="keyword">else</span> &#123;</div><div class="line">                  <span class="keyword">return</span> c2;</div><div class="line">              &#125;</div><div class="line">         &#125;</div><div class="line">         <span class="keyword">return</span> c1;</div><div class="line">     &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="自定义分区器"><a href="#自定义分区器" class="headerlink" title="自定义分区器"></a>自定义分区器</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.sxt.hadoop.mapreduce.weather;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WeatherPartitioner</span> <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">Weather</span>, <span class="title">Text</span>&gt;</span>&#123;</div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(Weather key,Text value,<span class="keyword">int</span> numReduceTasks)</span> </span>&#123;</div><div class="line">              <span class="keyword">return</span> (key.getYear()) % numReduceTasks;</div><div class="line">     &#125;</div><div class="line">&#125;</div><div class="line">自定义排序器</div><div class="line"><span class="keyword">package</span> com.sxt.hadoop.mapreduce.weather;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparator;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WeatherSort</span> <span class="keyword">extends</span> <span class="title">WritableComparator</span> </span>&#123;</div><div class="line">     </div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="title">WeatherSort</span><span class="params">()</span> </span>&#123;</div><div class="line">         <span class="keyword">super</span>(Weather.class,<span class="keyword">true</span>);</div><div class="line">     &#125;</div><div class="line">     </div><div class="line">     <span class="meta">@Override</span></div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> </span>&#123;</div><div class="line">         Weather w1 = (Weather) a;</div><div class="line">         Weather w2 = (Weather) b;</div><div class="line">         <span class="keyword">int</span> c1 = Integer.compare(w1.getYear(), w2.getYear());</div><div class="line">         <span class="keyword">if</span>(c1 == <span class="number">0</span>) &#123;</div><div class="line">              <span class="keyword">int</span> c2 = Integer.compare(w1.getMonth(), w2.getMonth());</div><div class="line">              <span class="keyword">if</span>(c2 == <span class="number">0</span>) &#123;</div><div class="line">                  <span class="keyword">int</span> c3 = Integer.compare(w1.getDay(), w2.getDay());</div><div class="line">                  <span class="keyword">if</span>(c3 == <span class="number">0</span>) &#123;</div><div class="line">                       <span class="keyword">return</span> - Integer.compare(</div><div class="line">w1.getTemperature(), w2.getTemperature());</div><div class="line">                  &#125;<span class="keyword">else</span> &#123;</div><div class="line">                       <span class="keyword">return</span> c3;</div><div class="line">                  &#125;</div><div class="line">              &#125;<span class="keyword">else</span> &#123;</div><div class="line">                  <span class="keyword">return</span> c2;</div><div class="line">              &#125;</div><div class="line">         &#125;</div><div class="line">         <span class="keyword">return</span> c1;</div><div class="line">     &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="自定义分组器"><a href="#自定义分组器" class="headerlink" title="自定义分组器"></a>自定义分组器</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.sxt.hadoop.mapreduce.weather;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparator;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WeatherGroup</span> <span class="keyword">extends</span> <span class="title">WritableComparator</span></span>&#123;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">WeatherGroup</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">super</span>(Weather.class, <span class="keyword">true</span>);</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> </span>&#123;</div><div class="line">		Weather w1 = (Weather) a;</div><div class="line">		Weather w2 = (Weather) b;</div><div class="line">		<span class="keyword">int</span> c1 = Integer.compare(w1.getYear(), w2.getYear());</div><div class="line">		<span class="keyword">if</span>(c1 == <span class="number">0</span>) &#123;</div><div class="line">			<span class="keyword">return</span> Integer.compare(w1.getMonth(), w2.getMonth());</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">return</span> c1;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="Mapper类-1"><a href="#Mapper类-1" class="headerlink" title="Mapper类"></a>Mapper类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.sxt.hadoop.mapreduce.weather;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</div><div class="line"><span class="keyword">import</span> java.util.Calendar;</div><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.StringUtils;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WeatherMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Weather</span>, <span class="title">Text</span>&gt;</span>&#123;</div><div class="line">     Weather w = <span class="keyword">new</span> Weather();</div><div class="line">     Text val = <span class="keyword">new</span> Text();</div><div class="line">     </div><div class="line">     <span class="meta">@Override</span></div><div class="line">     <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span></span></div><div class="line">              <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">         </div><div class="line">         <span class="keyword">try</span> &#123;</div><div class="line">              <span class="comment">// 1.读懂数据</span></div><div class="line">              String[] strs = StringUtils.split(value.toString(), <span class="string">'\t'</span>);</div><div class="line">              SimpleDateFormat sdf = </div><div class="line"><span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>);</div><div class="line">              Date date = <span class="keyword">null</span>;</div><div class="line">              Calendar cal = Calendar.getInstance();</div><div class="line">              date = sdf.parse(strs[<span class="number">0</span>]);</div><div class="line">              cal.setTime(date);</div><div class="line">              <span class="comment">// 2.映射K,V</span></div><div class="line">              w.setYear(cal.get(Calendar.YEAR));</div><div class="line">              w.setMonth((cal.get(Calendar.MONTH))+ <span class="number">1</span>);</div><div class="line">              w.setDay(cal.get(Calendar.DAY_OF_MONTH));</div><div class="line">              <span class="keyword">int</span> tem = Integer.parseInt(strs[<span class="number">1</span>]</div><div class="line">.substring(<span class="number">0</span>, strs[<span class="number">1</span>].lastIndexOf(<span class="string">"c"</span>)));</div><div class="line">              w.setTemperature(tem);</div><div class="line">              val.set(tem+<span class="string">""</span>);</div><div class="line">              </div><div class="line">              context.write(w, val);</div><div class="line">         &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">              e.printStackTrace();</div><div class="line">         &#125;</div><div class="line">         </div><div class="line">     &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="Reducer类-1"><a href="#Reducer类-1" class="headerlink" title="Reducer类"></a>Reducer类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.sxt.hadoop.mapreduce.weather;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WeatherReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Weather</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line">     </div><div class="line">     Text kout = <span class="keyword">new</span> Text();</div><div class="line">     IntWritable vout = <span class="keyword">new</span> IntWritable();</div><div class="line">     </div><div class="line">     <span class="meta">@Override</span></div><div class="line">     <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Weather key, Iterable&lt;Text&gt; vals, </span></span></div><div class="line">Context context) <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">         <span class="keyword">int</span> wd1 = <span class="number">0</span>;</div><div class="line">         <span class="keyword">int</span> wd2 = <span class="number">0</span>;</div><div class="line">         <span class="keyword">int</span> d1 = <span class="number">0</span>;</div><div class="line">         <span class="keyword">int</span> d2 = <span class="number">0</span>;</div><div class="line">         <span class="keyword">int</span> day = <span class="number">0</span>;</div><div class="line">         <span class="keyword">int</span> flg = <span class="number">0</span>;</div><div class="line">         </div><div class="line">         <span class="keyword">for</span> (Text val : vals) &#123;</div><div class="line">              <span class="comment">//首次</span></div><div class="line">              <span class="keyword">if</span> (flg == <span class="number">0</span>)&#123;</div><div class="line">                  day = key.getDay();</div><div class="line">                  d1 = day;</div><div class="line">                  wd1 =  key.getTemperature();</div><div class="line">                  flg++;</div><div class="line">              &#125;</div><div class="line">              <span class="comment">//第二次</span></div><div class="line">              <span class="keyword">if</span>(day != key.getDay()) &#123;</div><div class="line">                  <span class="comment">//是不是第三次之后</span></div><div class="line">                  <span class="keyword">if</span>(flg==<span class="number">1</span>)&#123;</div><div class="line">                       d2=key.getDay();</div><div class="line">                       wd2 = key.getTemperature();     </div><div class="line">                       flg++;</div><div class="line">                  &#125;<span class="keyword">else</span>&#123;</div><div class="line">                       <span class="comment">//先判断，温度有没有比缓存大的</span></div><div class="line">                       <span class="keyword">if</span> ( wd1 &gt; wd2   )&#123;</div><div class="line">                            <span class="keyword">if</span> (key.getTemperature()&gt; wd2)&#123;</div><div class="line">                                wd2=key.getTemperature();</div><div class="line">                                d2=key.getDay();                         </div><div class="line">                            &#125;</div><div class="line">                       &#125;<span class="keyword">else</span>&#123;</div><div class="line">                            <span class="keyword">if</span> (key.getTemperature()&gt; wd1)&#123;</div><div class="line">                                wd1=key.getTemperature();</div><div class="line">                                d1=key.getDay();                         </div><div class="line">                            &#125;</div><div class="line">                       &#125;</div><div class="line">                  &#125;</div><div class="line">              &#125;</div><div class="line">         &#125;</div><div class="line">         </div><div class="line">         kout.set(key.getYear()+<span class="string">"-"</span>+key.getMonth()+<span class="string">"-"</span>+d1);</div><div class="line">         vout.set(wd1);</div><div class="line">         context.write(kout, vout);</div><div class="line">         </div><div class="line">         <span class="keyword">if</span> (flg == <span class="number">2</span>)&#123;</div><div class="line">              </div><div class="line">              kout.set(key.getYear()+<span class="string">"-"</span>+key.getMonth()+<span class="string">"-"</span>+d2);</div><div class="line">              vout.set(wd2);</div><div class="line">              context.write(kout, vout);</div><div class="line">         &#125;</div><div class="line">     &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="Job类-1"><a href="#Job类-1" class="headerlink" title="Job类"></a>Job类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.sxt.hadoop.mapreduce.weather;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WeatherJob</span> </span>&#123;</div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">         Configuration conf = <span class="keyword">new</span> Configuration(<span class="keyword">true</span>);</div><div class="line">         <span class="comment">/*</span></div><div class="line">          * 本地模拟设置以下配置</div><div class="line">          * conf.set("mapreduce.app-submission.cross-platform", "true");</div><div class="line">          * conf.set("mapreduce.framework.name", "local");</div><div class="line">          * job.setJar("path/xxx.jar");</div><div class="line">          */</div><div class="line">         conf.set(<span class="string">"mapreduce.app-submission.cross-platform"</span>, <span class="string">"true"</span>);</div><div class="line">         conf.set(<span class="string">"mapreduce.framework.name"</span>, <span class="string">"local"</span>);</div><div class="line">         Job job = Job.getInstance(conf);</div><div class="line">         job.setJar(<span class="string">"E:\\package\\Weather.jar"</span>);</div><div class="line">         job.setJarByClass(WeatherJob.class);</div><div class="line">         </div><div class="line">         job.setMapperClass(WeatherMapper.class);</div><div class="line">         <span class="comment">// 使用自定义数据类型包装Key(年、月、日、温度),默认正序</span></div><div class="line">         job.setMapOutputKeyClass(Weather.class);</div><div class="line">         job.setMapOutputValueClass(Text.class);</div><div class="line">         </div><div class="line">         job.setNumReduceTasks(<span class="number">2</span>);</div><div class="line">         </div><div class="line">         <span class="comment">// 分区算法保证相同的Key为一组</span></div><div class="line">         <span class="comment">// 目的是将不同的Key分发到不同的Reduce</span></div><div class="line">         <span class="comment">// 按(年，月)计算分区号</span></div><div class="line">         <span class="comment">// 类似分组比较器，可以收敛计算宽度</span></div><div class="line">         <span class="comment">// 按(年)计算分区号</span></div><div class="line">          job.setPartitionerClass(WeatherPartitioner.class);</div><div class="line">         </div><div class="line">         <span class="comment">// 自定义排序比较器，倒序</span></div><div class="line">         job.setSortComparatorClass(WeatherSort.class);</div><div class="line">         <span class="comment">// 自定义分组边界，按年、月进行分组</span></div><div class="line">         job.setGroupingComparatorClass(WeatherGroup.class);</div><div class="line">         </div><div class="line">         job.setReducerClass(WeatherReducer.class);</div><div class="line">         Path input = <span class="keyword">new</span> Path(<span class="string">"/user/weather/input/weather.data"</span>);</div><div class="line">         FileInputFormat.addInputPath(job, input);</div><div class="line">         Path output = <span class="keyword">new</span> Path(<span class="string">"/user/weather/output"</span>);</div><div class="line">         <span class="keyword">if</span> (output.getFileSystem(conf).exists(output)) &#123;</div><div class="line">              output.getFileSystem(conf).delete(output, <span class="keyword">true</span>);</div><div class="line">         &#125;</div><div class="line">         FileOutputFormat.setOutputPath(job, output);</div><div class="line">         </div><div class="line">         job.waitForCompletion(<span class="keyword">true</span>);</div><div class="line">     &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="Hadoop案例：好友推荐"><a href="#Hadoop案例：好友推荐" class="headerlink" title="Hadoop案例：好友推荐"></a>Hadoop案例：好友推荐</h3><p><img src="/media/15048008791736.jpg" alt=""></p>
<table>
<thead>
<tr>
<th>本人</th>
<th>好友</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tom</td>
<td>Cat Hadoop Hello</td>
</tr>
<tr>
<td>Cat</td>
<td>Tom Hive </td>
</tr>
<tr>
<td>Hadoop</td>
<td>Tom Hive World</td>
</tr>
<tr>
<td>World</td>
<td>Hadoop Hive Hello</td>
</tr>
<tr>
<td>Hive</td>
<td>Hadoop Cat World MR Hello</td>
</tr>
<tr>
<td>Hello</td>
<td>Tom World Hive MR</td>
</tr>
<tr>
<td>MR</td>
<td>Hello Hive</td>
</tr>
</tbody>
</table>
<p>文件friend的内容如下：<br>Tom Hello Hadoop Cat<br>World Hadoop Hello Hive<br>Cat Tom Hive<br>MR Hive Hello<br>Hive Cat Hadoop World Hello MR<br>Hadoop Tom Hive World<br>Hello Tom World Hive MR</p>
<p>代码思路：<br>split后两两组合为key（例：Tom_Hello，这里还需要注意Tom_Hello与Hello_Tom，明显他们应该是相同的组合，但是hadoop可不会智能的将其识别为相同的key，所以组合之前先比较大小再按顺序组合，保证他们之间是相同的组合，即都是Helllo_Tom）,直接好友value为0，间接好友value为1，reduce中，出现1，则跳过这次计算。</p>
<h4 id="Job类-2"><a href="#Job类-2" class="headerlink" title="Job类"></a>Job类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">FoF</span> </span>&#123;</div><div class="line">     </div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">         Configuration conf = <span class="keyword">new</span> Configuration(<span class="keyword">true</span>);</div><div class="line">         <span class="comment">//在Windows环境中run mapreduce需要此条配置</span></div><div class="line">         <span class="comment">//除了GUN/Linux运行客户端都需要设置为true</span></div><div class="line">          conf.set(<span class="string">"mapreduce.app-submission.cross-platform"</span>, <span class="string">"true"</span>);</div><div class="line">         <span class="comment">//本地模拟需要此条配置，配置文件(mapred-site.xml)的值为 yarn</span></div><div class="line">         conf.set(<span class="string">"mapreduce.framework.name"</span>, <span class="string">"local"</span>);</div><div class="line">         Job job = Job.getInstance(conf);</div><div class="line">         </div><div class="line">         <span class="comment">//jar包是集群模式运行不可缺少的</span></div><div class="line">         job.setJarByClass(FoF.class);</div><div class="line">         <span class="comment">//本地多线程模拟不需要打jar包</span></div><div class="line">         <span class="comment">//job.setJar("E:\\package\\FoF.jar");</span></div><div class="line"></div><div class="line">         job.setMapperClass(FMapper.class);</div><div class="line">         job.setMapOutputKeyClass(Text.class);</div><div class="line">         job.setMapOutputValueClass(IntWritable.class);</div><div class="line">         </div><div class="line">         job.setReducerClass(FReducer.class);</div><div class="line">         </div><div class="line">         Path input = <span class="keyword">new</span> Path(<span class="string">"/user/friends/input"</span>);</div><div class="line">         FileInputFormat.addInputPath(job, input);</div><div class="line">         Path output = <span class="keyword">new</span> Path(<span class="string">"/user/friends/output"</span>);</div><div class="line">         <span class="keyword">if</span>(output.getFileSystem(conf).exists(output)) &#123;</div><div class="line">              output.getFileSystem(conf).delete(output, <span class="keyword">true</span>);</div><div class="line">         <span class="comment">/* true的意义：</span></div><div class="line">          * if path is a directory and set to true</div><div class="line">          * the directory is deleted else throws an exception.</div><div class="line">          * In case of a file the value can be set to either</div><div class="line">true or false</div><div class="line">          */</div><div class="line">         &#125;</div><div class="line">         FileOutputFormat.setOutputPath(job, output);</div><div class="line">         job.waitForCompletion(<span class="keyword">true</span>);</div><div class="line">     &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="Mapper类-2"><a href="#Mapper类-2" class="headerlink" title="Mapper类"></a>Mapper类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line">     Text mkey = <span class="keyword">new</span> Text();</div><div class="line">     IntWritable mvalue = <span class="keyword">new</span> IntWritable();</div><div class="line">     <span class="meta">@Override</span></div><div class="line">     <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, IntWritable&gt;.Context context)</span></span></div><div class="line">              <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">         <span class="comment">//Tom Cat Hadoop Hello</span></div><div class="line"><span class="comment">//输入一行数据，迭代后两两输出，输出时标注关系，直接好友:0，间接好友:1</span></div><div class="line">         String[] friends = </div><div class="line">StringUtils.split(value.toString(), <span class="string">' '</span>);</div><div class="line">         <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;friends.length; i++) &#123;</div><div class="line">              mkey.set(compare(friends[<span class="number">0</span>], friends[i]));</div><div class="line">              mvalue.set(<span class="number">0</span>);</div><div class="line">              <span class="comment">/*</span></div><div class="line">               * Tom-Tom 0</div><div class="line">               * Cat-Tom 0</div><div class="line">               * Hadoop-Tom 0</div><div class="line">               * Hello-Tom 0</div><div class="line">               */</div><div class="line">              context.write(mkey, mvalue);</div><div class="line">              <span class="keyword">for</span>(<span class="keyword">int</span> j = i+<span class="number">1</span>; j &lt; friends.length-<span class="number">1</span>; j++) &#123;</div><div class="line">    				mkey.set(compare(friends[i+<span class="number">1</span>], friends[j+<span class="number">1</span>]));</div><div class="line">    				mvalue.set(<span class="number">1</span>);</div><div class="line">    				<span class="comment">/*</span></div><div class="line">     				 * Cat-Hadoop 1</div><div class="line">     				 * Cat-Hello 1</div><div class="line">     				 * Hadoop-Hello 1</div><div class="line">     				 */</div><div class="line">      				context.write(mkey, mvalue);</div><div class="line">&#125;</div><div class="line">         &#125;</div><div class="line">     &#125;</div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">compare</span><span class="params">(String s1, String s2)</span> </span>&#123;</div><div class="line">         <span class="keyword">if</span>(s1.compareTo(s2) &gt; <span class="number">0</span>) &#123;</div><div class="line">              <span class="keyword">return</span> s2 + <span class="string">"-"</span> + s1;</div><div class="line">         &#125;<span class="keyword">else</span> &#123;</div><div class="line">              <span class="keyword">return</span> s1 + <span class="string">"-"</span> + s2;</div><div class="line">         &#125;</div><div class="line">     &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="Reducer类-2"><a href="#Reducer类-2" class="headerlink" title="Reducer类"></a>Reducer类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;</div><div class="line">     Text rvalue = <span class="keyword">new</span> Text();</div><div class="line">     </div><div class="line">     <span class="meta">@Override</span></div><div class="line">     <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, Text&gt;.Context context)</span></span></div><div class="line">              <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">         <span class="comment">//相同的key为一组，调用一次reduce</span></div><div class="line">         <span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">         <span class="keyword">int</span> flag = <span class="number">0</span>;</div><div class="line">         <span class="keyword">for</span>(IntWritable i : values) &#123;</div><div class="line">              sum += i.get();</div><div class="line">				  <span class="comment">//如果是直接好友，不再计算</span></div><div class="line">              <span class="keyword">if</span>(i.get() == <span class="number">0</span>) &#123;</div><div class="line">                  flag = <span class="number">1</span>;</div><div class="line">                  <span class="keyword">break</span>;</div><div class="line">              &#125;</div><div class="line">         &#125;</div><div class="line">         <span class="keyword">if</span>(flag == <span class="number">0</span>)&#123;</div><div class="line">              rvalue.set(sum + <span class="string">""</span>);</div><div class="line">               context.write(key, rvalue);</div><div class="line">         &#125;</div><div class="line">         </div><div class="line">     &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="服务器集群运行的两种方式"><a href="#服务器集群运行的两种方式" class="headerlink" title="服务器集群运行的两种方式"></a>服务器集群运行的两种方式</h4><ol>
<li>在Linux中运行<br>1)    打jar包，把jar发送到服务器，hadoop jar方式<br>2)    直接运行client代码<br>conf.set(“mapreduce.app-submission.cross-platform”, “true”);<br>job.setJar(“path”);</li>
<li>本地多线程模拟运行<br>conf.set(“mapreduce.framework.name”, “local”);<br>当Configuration conf = new Configuration(true);true值设置为false时，不需要配置”local”，因为Configuration conf = new Configuration(false)默认选择local模式。当Configuration conf = new Configuration(false)时，还需要读取配置文件的信息，需要手工设置，conf.set(“”, “”);</li>
</ol>
<h3 id="Hadoop案例：ItemCF"><a href="#Hadoop案例：ItemCF" class="headerlink" title="Hadoop案例：ItemCF"></a>Hadoop案例：ItemCF</h3><h4 id="协同过滤"><a href="#协同过滤" class="headerlink" title="协同过滤"></a>协同过滤</h4><p>商品推荐<br>思考：<br>购买成功后：购买了该商品的其他用户购买了以下商品<br>根据用户的实时行为<br>搜索成功后：您可能感兴趣的以下商品<br>根据用户的主观意识<br>主页或广告：您可能感兴趣的以下商品<br>根据用户的特征向量</p>
<p>推荐系统是基于协同过滤(Collaborative Filtering)算法来实现的，CF算法包括两种：</p>
<p>基于用户的系统过滤：UserCF<br><img src="/media/15048023651096.jpg" alt=""><br>基于用户的协同过滤，通过不同用户对物品的评分来评测用户之间的相似性，基于用户之间的相似性做出推荐。简单来讲就是：给用户推荐和他兴趣相似的其他用户喜欢的物品。</p>
<p>基于物品的协同过滤：ItemCF<br><img src="/media/15048024141264.jpg" alt=""></p>
<p>基于item的协同过滤，通过用户对不同item的评分来评测item之间的相似性，基于item之间的相似性做出推荐。简单来讲就是：给用户推荐和他之前喜欢的物品相似的物品。</p>
<h4 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h4><p>Co-occurrence Matrix(同现矩阵)和User Preference Vector(用户评分向量)相乘得到的这个Recommended Vector(推荐向量)<br>1.基于全量数据的统计，产生同现矩阵<br>体现商品间的关联性<br>每件商品都有自己对其他全部商品的关联性（每件商品的特征）<br>解释：<br>通过历史订单交易记录，计算得出每一件商品相对其他商品同时出现在同一订单的次数，所以每件商品都有自己相对全部商品的同现列表<br>2.用户评分向量体现的是用户对一些商品的评分<br>解释：<br>用户会对部分商品有过加入购物车，购买等实际操作，经过计算会得到用户对这部分商品的评分向量列表<br>3.任一商品需要<br>用户评分向量乘以基于该商品的其他商品关联值，求和得出针对该商品的推荐向量<br>解释：<br>使用用户评分向量列表中的分值，依次乘以每一件商品同现列表中该分值的代表物品的同现值，求和便是该物品的推荐向量，排序取TopN即可<br><img src="/media/15048024797603.jpg" alt=""></p>
<h5 id="求同现矩阵的方法："><a href="#求同现矩阵的方法：" class="headerlink" title="求同现矩阵的方法："></a>求同现矩阵的方法：</h5><p><img src="/media/15048025267839.jpg" alt=""></p>
<h5 id="求推荐向量（R值）方法："><a href="#求推荐向量（R值）方法：" class="headerlink" title="求推荐向量（R值）方法："></a>求推荐向量（R值）方法：</h5><p><img src="/media/15048025515448.jpg" alt=""></p>
<h4 id="MR思路"><a href="#MR思路" class="headerlink" title="MR思路"></a>MR思路</h4><p><img src="/media/15048025737557.jpg" alt=""></p>
<p>代码略……</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          
            <a href="/tags/hadoop原理及其搭建/" rel="tag"># hadoop原理及其搭建</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/10/13/Hive-DDl/" rel="next" title="Hive--DDL和DML练习">
                <i class="fa fa-chevron-left"></i> Hive--DDL和DML练习
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/11/28/ Hive学习笔记/" rel="prev" title="Hive学习笔记">
                Hive学习笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="Chant" />
          <p class="site-author-name" itemprop="name">Chant</p>
           
              <p class="site-description motion-element" itemprop="description">Take things as they are with a cavalier attitude./用漫不经心的态度过随遇而安的生活</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">33</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">17</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">38</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/Chant00" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.facebook.com/profile.php?id=100014951437344" target="_blank" title="Facebook">
                  
                    <i class="fa fa-fw fa-facebook"></i>
                  
                  Facebook
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.douban.com/people/63254896/" target="_blank" title="豆瓣">
                  
                    <i class="fa fa-fw fa-book"></i>
                  
                  豆瓣
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接：
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://isujin.com/" title="素锦" target="_blank">素锦</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://zhibimo.com/explore/books" title="知笔墨" target="_blank">知笔墨</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.danielaandrade.com/" title="Daniela Andrade" target="_blank">Daniela Andrade</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://yangyunhe.github.io/" title="晴空一鹤" target="_blank">晴空一鹤</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://poppinrain.github.io" title="焚膏继晷" target="_blank">焚膏继晷</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop的三大核心模块"><span class="nav-number">1.</span> <span class="nav-text">Hadoop的三大核心模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分布式存储系统HDFS"><span class="nav-number">2.</span> <span class="nav-text">分布式存储系统HDFS</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#存储模型"><span class="nav-number">2.1.</span> <span class="nav-text">存储模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#架构模型"><span class="nav-number">2.2.</span> <span class="nav-text">架构模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NameNode（NN）"><span class="nav-number">2.3.</span> <span class="nav-text">NameNode（NN）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DataNode（DN）"><span class="nav-number">2.4.</span> <span class="nav-text">DataNode（DN）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SecondaryNameNode（SNN）"><span class="nav-number">2.5.</span> <span class="nav-text">SecondaryNameNode（SNN）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Block的副本放置策略"><span class="nav-number">2.6.</span> <span class="nav-text">Block的副本放置策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS读流程"><span class="nav-number">2.7.</span> <span class="nav-text">HDFS读流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#安全模式"><span class="nav-number">2.8.</span> <span class="nav-text">安全模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS优点"><span class="nav-number">2.9.</span> <span class="nav-text">HDFS优点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS缺点"><span class="nav-number">2.10.</span> <span class="nav-text">HDFS缺点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pseudo-Distributed-Mode安装配置"><span class="nav-number">3.</span> <span class="nav-text">Pseudo-Distributed Mode安装配置</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-安装配置JDK"><span class="nav-number">3.0.0.1.</span> <span class="nav-text">1.    安装配置JDK</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-解压hadoop-2-6-5-tar-gz"><span class="nav-number">3.0.0.2.</span> <span class="nav-text">2.    解压hadoop-2.6.5.tar.gz</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-在环境变量中加入hadoop安装路径"><span class="nav-number">3.0.0.3.</span> <span class="nav-text">3.    在环境变量中加入hadoop安装路径</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#4-设置ssh登录本机免秘钥"><span class="nav-number">3.0.0.4.</span> <span class="nav-text">4.    设置ssh登录本机免秘钥</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#5-修改hadoop配置文件-env-sh"><span class="nav-number">3.0.0.5.</span> <span class="nav-text">5.    修改hadoop配置文件-env.sh</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#6-修改hadoop配置文件，配置伪分布式相关的内容"><span class="nav-number">3.0.0.6.</span> <span class="nav-text">6.    修改hadoop配置文件，配置伪分布式相关的内容</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#7-设置datanode在哪些节点"><span class="nav-number">3.0.0.7.</span> <span class="nav-text">7.    设置datanode在哪些节点</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#8-格式化文件系统"><span class="nav-number">3.0.0.8.</span> <span class="nav-text">8.    格式化文件系统</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#9-启动hdfs系统"><span class="nav-number">3.0.0.9.</span> <span class="nav-text">9.    启动hdfs系统</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#10-查看进程是否启动"><span class="nav-number">3.0.0.10.</span> <span class="nav-text">10.    查看进程是否启动</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#11-去网页验证"><span class="nav-number">3.0.0.11.</span> <span class="nav-text">11.去网页验证</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS的基本操作"><span class="nav-number">3.1.</span> <span class="nav-text">HDFS的基本操作</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-创建目录："><span class="nav-number">3.1.0.1.</span> <span class="nav-text">1.创建目录：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-上传文件："><span class="nav-number">3.1.0.2.</span> <span class="nav-text">2.上传文件：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-上传文件时指定块大小为1M"><span class="nav-number">3.1.0.3.</span> <span class="nav-text">3.上传文件时指定块大小为1M</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Fully-Distributed-Mode安装配置"><span class="nav-number">3.2.</span> <span class="nav-text">Fully-Distributed Mode安装配置</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#角色划分"><span class="nav-number">3.2.0.1.</span> <span class="nav-text">角色划分</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#准备工作"><span class="nav-number">3.2.0.2.</span> <span class="nav-text">准备工作</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#1-在每台node上安装jdk并配置环境变量"><span class="nav-number">3.2.0.3.</span> <span class="nav-text">1.在每台node上安装jdk并配置环境变量</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-配置免秘钥登录"><span class="nav-number">3.2.0.4.</span> <span class="nav-text">2.配置免秘钥登录</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-在node01中对hadoop的配置文件做修改"><span class="nav-number">3.2.0.5.</span> <span class="nav-text">3.    在node01中对hadoop的配置文件做修改</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#4-将node01的hadoop安装目录分发给其他节点"><span class="nav-number">3.2.0.6.</span> <span class="nav-text">4.将node01的hadoop安装目录分发给其他节点</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#5-格式化文件系统（只在第一次启动时格式化）"><span class="nav-number">3.2.0.7.</span> <span class="nav-text">5.格式化文件系统（只在第一次启动时格式化）</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#6-启动服务"><span class="nav-number">3.2.0.8.</span> <span class="nav-text">6.启动服务</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#7-进行一些操作"><span class="nav-number">3.2.0.9.</span> <span class="nav-text">7.进行一些操作</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop-2-0"><span class="nav-number">4.</span> <span class="nav-text">Hadoop 2.0</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#产生背景"><span class="nav-number">4.1.</span> <span class="nav-text">产生背景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hadoop-1-0和2-0架构比较"><span class="nav-number">4.2.</span> <span class="nav-text">Hadoop 1.0和2.0架构比较</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS-2-x"><span class="nav-number">4.3.</span> <span class="nav-text">HDFS 2.x</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS-2-x-Federation"><span class="nav-number">4.4.</span> <span class="nav-text">HDFS 2.x Federation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS-2-x-HA（High-Availability）"><span class="nav-number">4.5.</span> <span class="nav-text">HDFS 2.x HA（High Availability）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS-2-x-HA-搭建"><span class="nav-number">4.6.</span> <span class="nav-text">HDFS 2.x HA 搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-在node02上解压zookeeper包"><span class="nav-number">4.6.0.1.</span> <span class="nav-text">1.在node02上解压zookeeper包</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-修改-etc-profile文件，配置zookeeper路径"><span class="nav-number">4.6.0.2.</span> <span class="nav-text">2.修改/etc/profile文件，配置zookeeper路径</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-配置zookeeper"><span class="nav-number">4.6.0.3.</span> <span class="nav-text">3.配置zookeeper</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-配置node03和node04的zookeeper"><span class="nav-number">4.6.1.</span> <span class="nav-text">4.配置node03和node04的zookeeper</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#5-启动zookeeper集群"><span class="nav-number">4.6.1.1.</span> <span class="nav-text">5.启动zookeeper集群</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#6-配置hdfs，在Fully-Distributed-Mode基础上进行修改"><span class="nav-number">4.6.1.2.</span> <span class="nav-text">6.配置hdfs，在Fully-Distributed Mode基础上进行修改</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#7-修改hdfs-site-xml文件"><span class="nav-number">4.6.1.3.</span> <span class="nav-text">7.修改hdfs-site.xml文件</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#8-修改core-site-xml"><span class="nav-number">4.6.1.4.</span> <span class="nav-text">8.修改core-site.xml</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#9-给node02生成公钥并分发"><span class="nav-number">4.6.1.5.</span> <span class="nav-text">9.给node02生成公钥并分发</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#10-将hadoop文件夹分发"><span class="nav-number">4.6.1.6.</span> <span class="nav-text">10.将hadoop文件夹分发</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#11-启动JNN集群"><span class="nav-number">4.6.1.7.</span> <span class="nav-text">11.启动JNN集群</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#12-在node01中执行格式化"><span class="nav-number">4.6.1.8.</span> <span class="nav-text">12.在node01中执行格式化</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#13-在node02中执行如下命令"><span class="nav-number">4.6.1.9.</span> <span class="nav-text">13.在node02中执行如下命令</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#14-格式化zkfc"><span class="nav-number">4.6.1.10.</span> <span class="nav-text">14.格式化zkfc</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#15-启动hdfs集群"><span class="nav-number">4.6.1.11.</span> <span class="nav-text">15.启动hdfs集群</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop-API"><span class="nav-number">5.</span> <span class="nav-text">Hadoop API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce"><span class="nav-number">6.</span> <span class="nav-text">MapReduce</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#语义"><span class="nav-number">6.1.</span> <span class="nav-text">语义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce原理"><span class="nav-number">6.2.</span> <span class="nav-text">MapReduce原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce任务中Shuffle和排序的过程"><span class="nav-number">6.3.</span> <span class="nav-text">MapReduce任务中Shuffle和排序的过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce运行框架"><span class="nav-number">6.4.</span> <span class="nav-text">MapReduce运行框架</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Yarn资源调度"><span class="nav-number">6.5.</span> <span class="nav-text">Yarn资源调度</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#搭建基于yarn的mapreduce框架"><span class="nav-number">7.</span> <span class="nav-text">搭建基于yarn的mapreduce框架</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#角色划分-1"><span class="nav-number">7.1.</span> <span class="nav-text">角色划分</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-编辑mapred-site-xml"><span class="nav-number">7.1.0.1.</span> <span class="nav-text">1.编辑mapred-site.xml</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-编辑yarn-site-xml"><span class="nav-number">7.1.0.2.</span> <span class="nav-text">2.编辑yarn-site.xml</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-分发配置"><span class="nav-number">7.1.0.3.</span> <span class="nav-text">3.分发配置</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#4-启动yarn"><span class="nav-number">7.1.0.4.</span> <span class="nav-text">4.启动yarn</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#5-手工启动ResourceManager"><span class="nav-number">7.1.0.5.</span> <span class="nav-text">5.手工启动ResourceManager</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#运行框架自带的例子程序"><span class="nav-number">7.2.</span> <span class="nav-text">运行框架自带的例子程序</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop案例：WordCount"><span class="nav-number">8.</span> <span class="nav-text">Hadoop案例：WordCount</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Job类"><span class="nav-number">8.1.</span> <span class="nav-text">Job类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mapper类"><span class="nav-number">8.2.</span> <span class="nav-text">Mapper类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Reducer类"><span class="nav-number">8.3.</span> <span class="nav-text">Reducer类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#在集群中运行程序步骤"><span class="nav-number">8.4.</span> <span class="nav-text">在集群中运行程序步骤</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce源码分析"><span class="nav-number">9.</span> <span class="nav-text">MapReduce源码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Client"><span class="nav-number">9.1.</span> <span class="nav-text">Client</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#总结图"><span class="nav-number">9.1.1.</span> <span class="nav-text">总结图</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Job类的继承关系"><span class="nav-number">9.1.2.</span> <span class="nav-text">Job类的继承关系</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Map-input"><span class="nav-number">10.</span> <span class="nav-text">Map-input</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#总结"><span class="nav-number">10.0.1.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#总结图-1"><span class="nav-number">10.0.2.</span> <span class="nav-text">总结图</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Map-output"><span class="nav-number">11.</span> <span class="nav-text">Map-output</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#环形缓冲区"><span class="nav-number">11.1.</span> <span class="nav-text">环形缓冲区</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapTask类"><span class="nav-number">11.2.</span> <span class="nav-text">MapTask类</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#总结-1"><span class="nav-number">11.2.1.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#总结图-2"><span class="nav-number">11.2.2.</span> <span class="nav-text">总结图</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Reduce"><span class="nav-number">11.3.</span> <span class="nav-text">Reduce</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#ReduceTask"><span class="nav-number">11.3.1.</span> <span class="nav-text">ReduceTask</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#总结-2"><span class="nav-number">11.3.2.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop案例：Weather"><span class="nav-number">12.</span> <span class="nav-text">Hadoop案例：Weather</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义封装类"><span class="nav-number">12.1.</span> <span class="nav-text">自定义封装类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义分区器"><span class="nav-number">12.2.</span> <span class="nav-text">自定义分区器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义分组器"><span class="nav-number">12.3.</span> <span class="nav-text">自定义分组器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mapper类-1"><span class="nav-number">12.4.</span> <span class="nav-text">Mapper类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Reducer类-1"><span class="nav-number">12.5.</span> <span class="nav-text">Reducer类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Job类-1"><span class="nav-number">12.6.</span> <span class="nav-text">Job类</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop案例：好友推荐"><span class="nav-number">13.</span> <span class="nav-text">Hadoop案例：好友推荐</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Job类-2"><span class="nav-number">13.1.</span> <span class="nav-text">Job类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mapper类-2"><span class="nav-number">13.2.</span> <span class="nav-text">Mapper类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Reducer类-2"><span class="nav-number">13.3.</span> <span class="nav-text">Reducer类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#服务器集群运行的两种方式"><span class="nav-number">13.4.</span> <span class="nav-text">服务器集群运行的两种方式</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop案例：ItemCF"><span class="nav-number">14.</span> <span class="nav-text">Hadoop案例：ItemCF</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#协同过滤"><span class="nav-number">14.1.</span> <span class="nav-text">协同过滤</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#算法原理"><span class="nav-number">14.2.</span> <span class="nav-text">算法原理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#求同现矩阵的方法："><span class="nav-number">14.2.1.</span> <span class="nav-text">求同现矩阵的方法：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#求推荐向量（R值）方法："><span class="nav-number">14.2.2.</span> <span class="nav-text">求推荐向量（R值）方法：</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MR思路"><span class="nav-number">14.3.</span> <span class="nav-text">MR思路</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chant</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  







  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/three/three.min.js"></script>

  
  <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://chant00.com/2016/11/08/HADOOP--hadoop运行原理及其搭建/';
          this.page.identifier = '2016/11/08/HADOOP--hadoop运行原理及其搭建/';
          this.page.title = 'HADOOP--hadoop运行原理及其搭建';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://chant-1.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  








  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (search_path.endsWith("json")) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("7n9J9l0UCv4yQu1307uCu3oM-gzGzoHsz", "OUDiIhwsTbY8xOgAKOuYf7Xb");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  
  


  

  

</body>
</html>
